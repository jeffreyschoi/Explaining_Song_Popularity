{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook begins the steps for implementing the data into a RAG system. We give the LLM the user-inputed lyrics, and we then find the embedding, use FAISS to compare and grab k similar lyrics from our data, and the LLM predicts popularity and explain why given the popularity and audio features of the similar songs. \n",
    "\n",
    "There is sitll work to be done:\n",
    "\n",
    "- we use the LLM for prediciton and explinations. using a prediction model instead can lead to better reproducibility (consistant scores)\n",
    "- we currently use dummy lyric embedding and FAISS similarity functions\n",
    "- better prompting techniques\n",
    "- deep eval to evaluate the perforamnce of RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/lyric_embeddings/librosa_shard_0_clean_ml_with_emb.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Dict, Any\n\u001b[0;32m---> 10\u001b[0m pickle1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/lyric_embeddings/librosa_shard_0_clean_ml_with_emb.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m pickle2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/lyric_embeddings/librosa_shard_1_clean_ml_with_emb.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m pickle3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/lyric_embeddings/librosa_shard_2_clean_ml_with_emb.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/lyric_embeddings/librosa_shard_0_clean_ml_with_emb.pkl'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/lyric_embeddings/librosa_shard_0_clean_ml_with_emb.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Dict, Any\n\u001b[0;32m----> 7\u001b[0m pickle1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/lyric_embeddings/librosa_shard_0_clean_ml_with_emb.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m pickle2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/lyric_embeddings/librosa_shard_1_clean_ml_with_emb.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m pickle3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/lyric_embeddings/librosa_shard_2_clean_ml_with_emb.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/lyric_embeddings/librosa_shard_0_clean_ml_with_emb.pkl'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "pickle1 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_0_clean_ml_with_emb.pkl\")\n",
    "pickle2 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_1_clean_ml_with_emb.pkl\")\n",
    "pickle3 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_2_clean_ml_with_emb.pkl\")\n",
    "pickle4 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_3_clean_ml_with_emb.pkl\")\n",
    "pickle5 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_4_clean_ml_with_emb.pkl\")\n",
    "\n",
    "df = pd.concat([pickle1, pickle2, pickle3, pickle4, pickle5])\n",
    "\n",
    "# Dummy embedding funciton. Replace with real later\n",
    "def embed_lyrics(text: str) -> np.ndarray:\n",
    "    # Arbitrary dimension; doesn't matter since dummy retrieval ignores it\n",
    "    dim = 16\n",
    "    return np.zeros(dim, dtype=float)\n",
    "\n",
    "\n",
    "# Dummy FAISS funciton. Replace with real later\n",
    "def retrieve_similar_songs(query_embedding: np.ndarray, k: int = 5) -> List[Dict[str, Any]]:\n",
    "    n = len(df)\n",
    "    k = min(k, n)\n",
    "    # Random unique indices\n",
    "    indices = np.random.choice(n, size=k, replace=False)\n",
    "\n",
    "    neighbors = []\n",
    "    for idx in indices:\n",
    "        neighbors.append({\n",
    "            \"index\": int(idx),\n",
    "            \"similarity\": 1.0  # constant dummy similarity\n",
    "        })\n",
    "    return neighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_feature_cols = list(df.columns[df.columns.get_loc(\"duration\")+1:])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_neighbors(df, query_embedding, k=5):\n",
    "    raw_neighbors = retrieve_similar_songs(query_embedding, k=k)\n",
    "    neighbors = []\n",
    "\n",
    "    for n in raw_neighbors:\n",
    "        idx = n[\"index\"]\n",
    "        row = df.iloc[idx]\n",
    "\n",
    "        audio_features = {}\n",
    "\n",
    "        for col in audio_feature_cols:\n",
    "            val = row[col]\n",
    "\n",
    "            # keep if scalar\n",
    "            if np.isscalar(val):\n",
    "                audio_features[col] = float(val)\n",
    "            \n",
    "            # flatten if array\n",
    "            elif isinstance(val, np.ndarray):\n",
    "                val = val.flatten()\n",
    "                for j, v in enumerate(val):\n",
    "                    audio_features[f\"{col}_{j}\"] = float(v)\n",
    "            \n",
    "            # flatten if list\n",
    "            elif isinstance(val, list):\n",
    "                for j, v in enumerate(val):\n",
    "                    audio_features[f\"{col}_{j}\"] = float(v)\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    audio_features[col] = float(val)\n",
    "                except Exception:\n",
    "                    audio_features[col] = None\n",
    "\n",
    "        neighbor_data = {\n",
    "            \"song_id\": row[\"song_id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"artist\": row[\"artist\"],\n",
    "            \"similarity\": n.get(\"similarity\", None),\n",
    "            \"popularity\": float(row[\"popularity\"]),\n",
    "            \"lyrics_snippet\": row[\"lyrics\"][:400].replace(\"\\n\", \" \") + \"...\",\n",
    "            \"audio_features\": audio_features\n",
    "        }\n",
    "        \n",
    "        neighbors.append(neighbor_data)\n",
    "\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue working on promping\n",
    "def build_rag_prompt_for_lyric_popularity(user_lyric: str,neighbors: List[Dict[str, Any]]) -> str:\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"You are an expert in music analytics, audio features, and lyric interpretation.\")\n",
    "    lines.append(\"You are given a NEW lyric and several similar songs from a dataset.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Each similar song includes:\")\n",
    "    lines.append(\" - song_id, title, artist\")\n",
    "    lines.append(\" - lyric snippet\")\n",
    "    lines.append(\" - popularity score (0-100)\")\n",
    "    lines.append(\" - detailed audio features extracted from 30-second clips\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Your tasks are:\")\n",
    "    lines.append(\"  1. Predict a popularity score (0-100) for the NEW lyric.\")\n",
    "    lines.append(\"  2. Explain your reasoning using comparisons to the similar songs.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Keep in mind the audio features of the similar songs, and explain what they mean in context to everyday people.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Return your answer as VALID JSON with this exact format:\")\n",
    "    lines.append(\"{\")\n",
    "    lines.append('  \"predicted_popularity\": <number>,')\n",
    "    lines.append('  \"explanation\": \"<multi-paragraph explanation grounded in the provided songs>\"')\n",
    "    lines.append(\"}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"IMPORTANT:\")\n",
    "    lines.append(\"Return ONLY raw JSON.\")\n",
    "    lines.append(\"Do NOT include any code fences such as ``` json\")\n",
    "    lines.append(\"Do NOT include any explanation text outside the JSON.\")\n",
    "    lines.append(\"Do NOT add commentary before or after the JSON.\")\n",
    "    lines.append(\"Return JSON ONLY.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\"NEW LYRIC:\")\n",
    "    lines.append(user_lyric.strip())\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"SIMILAR SONGS FROM THE DATASET (use these as evidence):\")\n",
    "\n",
    "    for i, nb in enumerate(neighbors, start=1):\n",
    "        lines.append(f\"\\nNeighbor #{i}:\")\n",
    "        lines.append(f\"  song_id: {nb['song_id']}\")\n",
    "        lines.append(f\"  title: {nb['title']}\")\n",
    "        lines.append(f\"  artist: {nb['artist']}\")\n",
    "        if nb[\"similarity\"] is not None:\n",
    "            lines.append(f\"  similarity: {nb['similarity']:.4f}\")\n",
    "        lines.append(f\"  popularity: {nb['popularity']:.2f}\")\n",
    "        lines.append(f\"  lyrics_snippet: {nb['lyrics_snippet']}\")\n",
    "        lines.append(\"  audio_features:\")\n",
    "\n",
    "        for feat_name, feat_val in nb[\"audio_features\"].items():\n",
    "            lines.append(f\"    {feat_name}: {feat_val:.4f}\")\n",
    "\n",
    "    lines.append(\"\")\n",
    "    lines.append(\n",
    "        \"Using ONLY the information above, estimate the popularity of the new lyric \"\n",
    "        \"and explain your reasoning in terms of lyric similarity, artist/genre patterns, \"\n",
    "        \"and audio features (energy, brightness, tempo, chroma, MFCCs, contrasts, tonnetz, etc.).\"\n",
    "        \"Make sure to contextulize what the audio features mean for the average person.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "def call_llm_for_popularity_and_explanation(prompt: str) -> dict:\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=prompt,\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=900\n",
    "    )\n",
    "\n",
    "    raw_text = response.output[0].content[0].text.strip()\n",
    "\n",
    "    # Remove any ```json ...``` or ```\n",
    "    raw_text = raw_text.replace(\"```json\", \"\")\n",
    "    raw_text = raw_text.replace(\"```\", \"\")\n",
    "    raw_text = raw_text.strip()\n",
    "\n",
    "    # first try direct json parse\n",
    "    try:\n",
    "        return json.loads(raw_text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # else, find outside json block using regex\n",
    "    json_matches = re.findall(r\"\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\}\", raw_text, flags=re.DOTALL)\n",
    "\n",
    "    if json_matches:\n",
    "        for match in json_matches:\n",
    "            try:\n",
    "                return json.loads(match)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # try to repair json with trailing commas\n",
    "    repaired = re.sub(r\",\\s*([}\\]])\", r\"\\1\", raw_text)\n",
    "\n",
    "    try:\n",
    "        return json.loads(repaired)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # else, say failed\n",
    "    print(\"Could not parse JSON from LLM output. Returning raw text.\")\n",
    "    return {\n",
    "        \"predicted_popularity\": None,\n",
    "        \"explanation\": raw_text\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_lyric_popularity_system(df: pd.DataFrame, user_lyric: str, k_neighbors: int = 5) -> Dict[str, Any]:\n",
    "    # 1) embed\n",
    "    query_embedding = embed_lyrics(user_lyric)\n",
    "\n",
    "    # 2) find songs with similar sounding lyrics\n",
    "    neighbors = get_top_k_neighbors(df, query_embedding, k=k_neighbors)\n",
    "\n",
    "    # 3) build prompt\n",
    "    prompt = build_rag_prompt_for_lyric_popularity(user_lyric, neighbors)\n",
    "\n",
    "    # 4) call llm\n",
    "    llm_output = call_llm_for_popularity_and_explanation(prompt)\n",
    "\n",
    "    pred_pop = llm_output.get(\"predicted_popularity\", None)\n",
    "    explanation = llm_output.get(\"explanation\", \"\")\n",
    "\n",
    "    return {\n",
    "        \"predicted_popularity\": pred_pop,\n",
    "        \"explanation\": explanation,\n",
    "        \"neighbors_used\": neighbors,\n",
    "        \"prompt_sent\": prompt,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can test the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lyric = \"random test lyrics.\"\n",
    "result = rag_lyric_popularity_system(df, test_lyric, k_neighbors=3)\n",
    "\n",
    "print(\"Predicted popularity:\", result[\"predicted_popularity\"])\n",
    "print(\"\\nExplanation:\\n\", result[\"explanation\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
