{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6babbd41-4024-41df-b72f-888cecf73eaf",
   "metadata": {},
   "source": [
    "### Import sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88029aa8-5a76-44c9-b063-e7808dd19581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /ext3/miniconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable:\", sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefde878-df70-4382-8d33-53ffeff86ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in /ext3/miniconda3/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /ext3/miniconda3/lib/python3.13/site-packages (from sentence-transformers) (2.8.0)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.1.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /ext3/miniconda3/lib/python3.13/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /ext3/miniconda3/lib/python3.13/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /ext3/miniconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /ext3/miniconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /ext3/miniconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2025.11.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /ext3/miniconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /ext3/miniconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /ext3/miniconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /ext3/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /ext3/miniconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ext3/miniconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.13/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading scikit_learn-1.7.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m153.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, safetensors, regex, pyyaml, joblib, hf-xet, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [huggingface-hub]\u001b[33m  WARNING: The scripts hf, huggingface-cli and tiny-agents are installed in '/home/gta3090/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [transformers]\u001b[33m  WARNING: The scripts transformers and transformers-cli are installed in '/home/gta3090/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/12\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.2.0 huggingface-hub-0.36.0 joblib-1.5.2 pyyaml-6.0.3 regex-2025.11.3 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.16.3 sentence-transformers-5.1.2 threadpoolctl-3.6.0 tokenizers-0.22.1 transformers-4.57.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Use the *same* python that the kernel is using:\n",
    "!{sys.executable} -m pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75a5db6-4bb1-40da-a4bc-3ea3c31809c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3631db45-d488-4d8c-b0a4-d45dac0e8987",
   "metadata": {},
   "source": [
    "### Preview all pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec0ae34-4907-4b1b-94b6-aa6a547b5205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'pandas.core.frame.DataFrame'>\n",
      "   song_id                title         artist          query_title  \\\n",
      "0     4845        State of Mind        Scooter        state of mind   \n",
      "1      462             Reptilia    The Strokes             reptilia   \n",
      "2    16017  None Of My Business     Cher Lloyd  none of my business   \n",
      "3     9478     Trouble Sleeping  The Perishers     trouble sleeping   \n",
      "4     2822     Shot in the Dark  Ozzy Osbourne     shot in the dark   \n",
      "\n",
      "    query_artist track_genre  popularity  \\\n",
      "0        scooter       happy        24.0   \n",
      "1    the strokes    alt-rock        75.0   \n",
      "2     cher lloyd     electro        64.0   \n",
      "3  the perishers    acoustic        48.0   \n",
      "4  ozzy osbourne   hard-rock        65.0   \n",
      "\n",
      "                                              lyrics  \\\n",
      "0  The world seems not the same...\\n\\nIntroducing...   \n",
      "1  [Verse 1]\\nHe seemed impressed by the way you ...   \n",
      "2  [Chorus]\\nDamn, I heard that you and her been ...   \n",
      "3  I'm having trouble sleeping\\nYou're jumping in...   \n",
      "4  [Verse 1]\\nOut on the streets I'm stalking the...   \n",
      "\n",
      "                                         preview_url    track_id  ...  \\\n",
      "0  https://audio-ssl.itunes.apple.com/itunes-asse...  1692327616  ...   \n",
      "1  https://audio-ssl.itunes.apple.com/itunes-asse...   302987569  ...   \n",
      "2  https://audio-ssl.itunes.apple.com/itunes-asse...  1438630505  ...   \n",
      "3  https://audio-ssl.itunes.apple.com/itunes-asse...    89335271  ...   \n",
      "4  https://audio-ssl.itunes.apple.com/itunes-asse...   158711416  ...   \n",
      "\n",
      "  spectral_contrast_4  spectral_contrast_5 spectral_contrast_6  \\\n",
      "0           20.798407            20.426306           18.328021   \n",
      "1           15.921962            18.347155           17.382681   \n",
      "2           18.045995            19.844230           18.248683   \n",
      "3           17.768873            20.125185           16.969837   \n",
      "4           15.990772            16.834263           17.184653   \n",
      "\n",
      "   spectral_contrast_7  tonnetz_1  tonnetz_2  tonnetz_3  tonnetz_4  tonnetz_5  \\\n",
      "0            39.053367   0.197966  -0.116721   0.142559  -0.069539  -0.044986   \n",
      "1            39.012014   0.078138  -0.077754   0.063345   0.036541  -0.011976   \n",
      "2            39.966514   0.013912   0.172900  -0.092766  -0.056323  -0.004173   \n",
      "3            28.947224  -0.118755   0.195544   0.025169  -0.130705   0.024176   \n",
      "4            35.540522  -0.113671   0.023209  -0.029743  -0.051142   0.003486   \n",
      "\n",
      "  tonnetz_6  \n",
      "0 -0.047523  \n",
      "1 -0.014041  \n",
      "2 -0.014388  \n",
      "3  0.005865  \n",
      "4 -0.011837  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-2988080/ipykernel_735203/3067213024.py:4: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  obj = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"librosa_shard_0.pkl\", \"rb\") as f:\n",
    "    obj = pickle.load(f)\n",
    "\n",
    "print(\"Type:\", type(obj))\n",
    "\n",
    "if isinstance(obj, dict):\n",
    "    print(\"Keys:\", obj.keys())\n",
    "\n",
    "elif isinstance(obj, list):\n",
    "    print(\"Length:\", len(obj))\n",
    "\n",
    "elif hasattr(obj, \"head\"):  # DataFrame-like\n",
    "    print(obj.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72748900-e8b1-40f7-92d3-76beb7fa689d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librosa_shard_1.pkl : DataFrame (4148, 95)\n",
      "Index(['song_id', 'title', 'artist', 'query_title', 'query_artist',\n",
      "       'track_genre', 'popularity', 'lyrics', 'preview_url', 'track_id'],\n",
      "      dtype='object')\n",
      "librosa_shard_2.pkl : DataFrame (4148, 95)\n",
      "Index(['song_id', 'title', 'artist', 'query_title', 'query_artist',\n",
      "       'track_genre', 'popularity', 'lyrics', 'preview_url', 'track_id'],\n",
      "      dtype='object')\n",
      "librosa_shard_3.pkl : DataFrame (4148, 95)\n",
      "Index(['song_id', 'title', 'artist', 'query_title', 'query_artist',\n",
      "       'track_genre', 'popularity', 'lyrics', 'preview_url', 'track_id'],\n",
      "      dtype='object')\n",
      "librosa_shard_4.pkl : DataFrame (4148, 95)\n",
      "Index(['song_id', 'title', 'artist', 'query_title', 'query_artist',\n",
      "       'track_genre', 'popularity', 'lyrics', 'preview_url', 'track_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for fname in [\"librosa_shard_1.pkl\", \"librosa_shard_2.pkl\", \"librosa_shard_3.pkl\", \"librosa_shard_4.pkl\"]:\n",
    "    try:\n",
    "        obj = pd.read_pickle(fname)\n",
    "        print(fname, \": DataFrame\", obj.shape)\n",
    "        print(obj.columns[:10])\n",
    "    except Exception:\n",
    "        with open(fname, \"rb\") as f:\n",
    "            obj = pickle.load(f)\n",
    "            print(fname, \": type\", type(obj))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ad54a-584a-41aa-9f23-f0767ee23fb5",
   "metadata": {},
   "source": [
    "## This cleaning function for lyrics will:\n",
    "\n",
    "- Lowercase everything\n",
    "- Remove [Chorus], [Verse 1], [Bridge], etc.\n",
    "- Replace \\n and \\\\n with spaces\n",
    "- Strip (prod. ...), (remix), etc.\n",
    "- Remove x2, x3 repeat markers\n",
    "- Keep letters, numbers, apostrophes, and spaces\n",
    "- Collapse extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b5b6be-6e5c-4767-9e1a-1a40cdcf6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_lyrics(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove Genius-style headers [chorus], [verse 1], [bridge], etc.\n",
    "    text = re.sub(r\"\\[.*?\\]\", \" \", text)\n",
    "\n",
    "    # normalize newlines: handle both real and escaped \"\\n\"\n",
    "    text = text.replace(\"\\\\n\", \" \").replace(\"\\n\", \" \")\n",
    "\n",
    "    # remove things like (prod. xxx), (remix)\n",
    "    text = re.sub(r\"\\(.*?prod.*?\\)\", \" \", text)\n",
    "    text = re.sub(r\"\\(.*?remix.*?\\)\", \" \", text)\n",
    "\n",
    "    # remove repeat indicators like \"x2\", \"x3\"\n",
    "    text = re.sub(r\"\\bx\\d+\\b\", \" \", text)\n",
    "\n",
    "    # keep only letters, numbers, apostrophes, spaces\n",
    "    text = re.sub(r\"[^a-z0-9' ]+\", \" \", text)\n",
    "\n",
    "    # collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46fd17e2-7dd3-42fc-b786-75dfe330083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following .pkl files:\n",
      "  - librosa_shard_0.pkl\n",
      "  - librosa_shard_1.pkl\n",
      "  - librosa_shard_2.pkl\n",
      "  - librosa_shard_3.pkl\n",
      "  - librosa_shard_4.pkl\n",
      "\n",
      "==============================\n",
      "Processing file: librosa_shard_0.pkl\n",
      "  Loaded DataFrame with shape: (4148, 95)\n",
      "  Cleaning lyrics (multilingual-safe)...\n",
      "  Sample before/after:\n",
      "                                              lyrics  \\\n",
      "0  The world seems not the same...\\n\\nIntroducing...   \n",
      "1  [Verse 1]\\nHe seemed impressed by the way you ...   \n",
      "2  [Chorus]\\nDamn, I heard that you and her been ...   \n",
      "\n",
      "                                        lyrics_clean  \n",
      "0  the world seems not the same introducing twist...  \n",
      "1  he seemed impressed by the way you came in tel...  \n",
      "2  damn i heard that you and her been having prob...  \n",
      "  Saved cleaned DataFrame to: librosa_shard_0_clean_ml.pkl\n",
      "\n",
      "==============================\n",
      "Processing file: librosa_shard_1.pkl\n",
      "  Loaded DataFrame with shape: (4148, 95)\n",
      "  Cleaning lyrics (multilingual-safe)...\n",
      "  Sample before/after:\n",
      "                                              lyrics  \\\n",
      "0  [Verse 1]\\nYou’re telling everybody I’m the on...   \n",
      "1  Well it takes time to be free\\nEverything chan...   \n",
      "2  You are now under mind control\\nYou are now un...   \n",
      "\n",
      "                                        lyrics_clean  \n",
      "0  you’re telling everybody i’m the one but you a...  \n",
      "1  well it takes time to be free everything chang...  \n",
      "2  you are now under mind control you are now und...  \n",
      "  Saved cleaned DataFrame to: librosa_shard_1_clean_ml.pkl\n",
      "\n",
      "==============================\n",
      "Processing file: librosa_shard_2.pkl\n",
      "  Loaded DataFrame with shape: (4148, 95)\n",
      "  Cleaning lyrics (multilingual-safe)...\n",
      "  Sample before/after:\n",
      "                                              lyrics  \\\n",
      "0  [Refrão x2]\\nHá sempre um lado que pesa\\nE out...   \n",
      "1  You keep saying you love him\\nI believe that i...   \n",
      "2  [Verse 1]\\nSo I told you what's wrong\\nAnd wit...   \n",
      "\n",
      "                                        lyrics_clean  \n",
      "0  há sempre um lado que pesa e outro lado que fl...  \n",
      "1  you keep saying you love him i believe that it...  \n",
      "2  so i told you what's wrong and with totally bl...  \n",
      "  Saved cleaned DataFrame to: librosa_shard_2_clean_ml.pkl\n",
      "\n",
      "==============================\n",
      "Processing file: librosa_shard_3.pkl\n",
      "  Loaded DataFrame with shape: (4148, 95)\n",
      "  Cleaning lyrics (multilingual-safe)...\n",
      "  Sample before/after:\n",
      "                                              lyrics  \\\n",
      "0  [Verse 1]\\nMy secrets are burning a hole throu...   \n",
      "1  [Instrumental Intro]\\n\\nHere we go, the people...   \n",
      "2  On a Greyhound bus full of runaway girls\\nTryi...   \n",
      "\n",
      "                                        lyrics_clean  \n",
      "0  my secrets are burning a hole through my heart...  \n",
      "1  here we go the people show victims of tomorrow...  \n",
      "2  on a greyhound bus full of runaway girls tryin...  \n",
      "  Saved cleaned DataFrame to: librosa_shard_3_clean_ml.pkl\n",
      "\n",
      "==============================\n",
      "Processing file: librosa_shard_4.pkl\n",
      "  Loaded DataFrame with shape: (4148, 95)\n",
      "  Cleaning lyrics (multilingual-safe)...\n",
      "  Sample before/after:\n",
      "                                              lyrics  \\\n",
      "0  [Intro: Jaira Burns, Soyeon & Lexie Liu]\\nK/DA...   \n",
      "1  [Verse 1]\\nYou heal the broken hearted\\nYou se...   \n",
      "2  [Verse 1: Chris James]\\nHappy life with the ma...   \n",
      "\n",
      "                                        lyrics_clean  \n",
      "0  kda should we show 'em how we do it every day ...  \n",
      "1  you heal the broken hearted you set the captiv...  \n",
      "2  happy life with the machines scattered around ...  \n",
      "  Saved cleaned DataFrame to: librosa_shard_4_clean_ml.pkl\n",
      "\n",
      "Done processing all .pkl files with multilingual cleaner.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- 1. Multilingual-friendly cleaning function ----------\n",
    "\n",
    "def clean_lyrics_multilingual(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove Genius-style headers [chorus], [verse 1], [bridge], etc.\n",
    "    text = re.sub(r\"\\[.*?\\]\", \" \", text)\n",
    "\n",
    "    # normalize newlines: handle both real and escaped \"\\n\"\n",
    "    text = text.replace(\"\\\\n\", \" \").replace(\"\\n\", \" \")\n",
    "\n",
    "    # remove things like (prod. xxx), (remix)\n",
    "    text = re.sub(r\"\\(.*?prod.*?\\)\", \" \", text)\n",
    "    text = re.sub(r\"\\(.*?remix.*?\\)\", \" \", text)\n",
    "\n",
    "    # remove repeat indicators like \"x2\", \"x3\"\n",
    "    text = re.sub(r\"\\bx\\d+\\b\", \" \", text)\n",
    "\n",
    "    # keep all letters (any language), digits, spaces, apostrophes\n",
    "    cleaned_chars = []\n",
    "    for ch in text:\n",
    "        cat = unicodedata.category(ch)\n",
    "        if cat.startswith(\"L\") or cat.startswith(\"N\") or ch in [\" \", \"'\", \"’\"]:\n",
    "            cleaned_chars.append(ch)\n",
    "\n",
    "    text = \"\".join(cleaned_chars)\n",
    "\n",
    "    # collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# ---------- 2. Root folder with all .pkl files ----------\n",
    "\n",
    "ROOT = Path(\"/scratch/gta3090/LLM_Final_Project_Datasets\") \n",
    "\n",
    "pkl_paths = sorted(ROOT.glob(\"*.pkl\"))\n",
    "\n",
    "print(\"Found the following .pkl files:\")\n",
    "for p in pkl_paths:\n",
    "    print(\"  -\", p.name)\n",
    "\n",
    "if not pkl_paths:\n",
    "    raise SystemExit(\"No .pkl files found in the folder. Check ROOT path.\")\n",
    "\n",
    "\n",
    "# ---------- 3. Loop and create *_clean_ml.pkl where lyrics exist ----------\n",
    "\n",
    "for pkl_path in pkl_paths:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"Processing file: {pkl_path.name}\")\n",
    "\n",
    "    # we'll write a new file like librosa_shard_0_clean_ml.pkl\n",
    "    out_path = pkl_path.with_name(pkl_path.stem + \"_clean_ml.pkl\")\n",
    "\n",
    "    if out_path.exists():\n",
    "        print(f\"  Skipping: {out_path.name} already exists.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = pd.read_pickle(pkl_path)\n",
    "    except Exception as e:\n",
    "        print(f\"  Could not read {pkl_path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if \"lyrics\" not in df.columns:\n",
    "        print(\"  Skipping: no 'lyrics' column in this file.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  Loaded DataFrame with shape: {df.shape}\")\n",
    "    print(\"  Cleaning lyrics (multilingual-safe)...\")\n",
    "\n",
    "    df[\"lyrics_clean\"] = df[\"lyrics\"].apply(clean_lyrics_multilingual)\n",
    "\n",
    "    print(\"  Sample before/after:\")\n",
    "    print(df[[\"lyrics\", \"lyrics_clean\"]].head(3))\n",
    "\n",
    "    df.to_pickle(out_path)\n",
    "    print(f\"  Saved cleaned DataFrame to: {out_path.name}\")\n",
    "\n",
    "print(\"\\nDone processing all .pkl files with multilingual cleaner.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb1b19-9d9c-4ba6-925f-035d48572a19",
   "metadata": {},
   "source": [
    "## Embedding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af390fe0-123d-40cf-a2a0-7db895b2a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding model: sentence-transformers/distiluse-base-multilingual-cased-v2\n",
      "\n",
      "==============================\n",
      "Processing shard: librosa_shard_0_clean_ml.pkl\n",
      "  Loaded DataFrame with shape: (4148, 96)\n",
      "  Number of rows to embed: 4148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embedding matrix shape: (4148, 512)\n",
      "  Saved embeddings matrix to: librosa_shard_0_clean_ml_embeddings.npy\n",
      "  Saved DataFrame with embeddings to: librosa_shard_0_clean_ml_with_emb.pkl\n",
      "\n",
      "==============================\n",
      "Processing shard: librosa_shard_1_clean_ml.pkl\n",
      "  Loaded DataFrame with shape: (4148, 96)\n",
      "  Number of rows to embed: 4148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embedding matrix shape: (4148, 512)\n",
      "  Saved embeddings matrix to: librosa_shard_1_clean_ml_embeddings.npy\n",
      "  Saved DataFrame with embeddings to: librosa_shard_1_clean_ml_with_emb.pkl\n",
      "\n",
      "==============================\n",
      "Processing shard: librosa_shard_2_clean_ml.pkl\n",
      "  Loaded DataFrame with shape: (4148, 96)\n",
      "  Number of rows to embed: 4148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embedding matrix shape: (4148, 512)\n",
      "  Saved embeddings matrix to: librosa_shard_2_clean_ml_embeddings.npy\n",
      "  Saved DataFrame with embeddings to: librosa_shard_2_clean_ml_with_emb.pkl\n",
      "\n",
      "==============================\n",
      "Processing shard: librosa_shard_3_clean_ml.pkl\n",
      "  Loaded DataFrame with shape: (4148, 96)\n",
      "  Number of rows to embed: 4148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embedding matrix shape: (4148, 512)\n",
      "  Saved embeddings matrix to: librosa_shard_3_clean_ml_embeddings.npy\n",
      "  Saved DataFrame with embeddings to: librosa_shard_3_clean_ml_with_emb.pkl\n",
      "\n",
      "==============================\n",
      "Processing shard: librosa_shard_4_clean_ml.pkl\n",
      "  Loaded DataFrame with shape: (4148, 96)\n",
      "  Number of rows to embed: 4148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embedding matrix shape: (4148, 512)\n",
      "  Saved embeddings matrix to: librosa_shard_4_clean_ml_embeddings.npy\n",
      "  Saved DataFrame with embeddings to: librosa_shard_4_clean_ml_with_emb.pkl\n",
      "\n",
      "All shards processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ---------- 1. Paths & model ----------\n",
    "\n",
    "ROOT = Path(\"/scratch/gta3090/LLM_Final_Project_Datasets\")\n",
    "\n",
    "# multilingual model (good for all languages)\n",
    "model_name = \"sentence-transformers/distiluse-base-multilingual-cased-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "print(f\"Loaded embedding model: {model_name}\")\n",
    "\n",
    "# ---------- 2. Loop over shards 0..4 ----------\n",
    "\n",
    "for shard_idx in range(5):\n",
    "    shard_name = f\"librosa_shard_{shard_idx}_clean_ml.pkl\"\n",
    "    shard_path = ROOT / shard_name\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"Processing shard: {shard_name}\")\n",
    "\n",
    "    if not shard_path.exists():\n",
    "        print(f\"  File not found: {shard_path} (skipping)\")\n",
    "        continue\n",
    "\n",
    "    # load DataFrame\n",
    "    df = pd.read_pickle(shard_path)\n",
    "    print(f\"  Loaded DataFrame with shape: {df.shape}\")\n",
    "\n",
    "    # check for cleaned lyrics\n",
    "    if \"lyrics_clean\" not in df.columns:\n",
    "        if \"lyrics\" in df.columns:\n",
    "            print(\"  WARNING: 'lyrics_clean' not found, falling back to 'lyrics'.\")\n",
    "            texts = df[\"lyrics\"].fillna(\"\").astype(str).tolist()\n",
    "        else:\n",
    "            print(\"  No 'lyrics_clean' or 'lyrics' column found. Skipping.\")\n",
    "            continue\n",
    "    else:\n",
    "        texts = df[\"lyrics_clean\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    print(f\"  Number of rows to embed: {len(texts)}\")\n",
    "\n",
    "    # ---------- 3. Compute embeddings in batches ----------\n",
    "    batch_size = 32\n",
    "    all_embs = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        embs = model.encode(\n",
    "            batch,\n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=True,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,  # nice for cosine similarity later\n",
    "        )\n",
    "        all_embs.append(embs)\n",
    "\n",
    "    embeddings = np.vstack(all_embs)  # shape: (num_rows, 512)\n",
    "    print(\"  Embedding matrix shape:\", embeddings.shape)\n",
    "\n",
    "    # ---------- 4. Save outputs ----------\n",
    "\n",
    "    # (A) Save as .npy matrix (optional but handy)\n",
    "    emb_npy_path = shard_path.with_name(shard_path.stem + \"_embeddings.npy\")\n",
    "    np.save(emb_npy_path, embeddings)\n",
    "    print(f\"  Saved embeddings matrix to: {emb_npy_path.name}\")\n",
    "\n",
    "    # (B) Attach to DataFrame as a column and save a new .pkl\n",
    "    df[\"lyrics_embedding\"] = list(embeddings)\n",
    "    out_pkl = shard_path.with_name(shard_path.stem + \"_with_emb.pkl\")\n",
    "    df.to_pickle(out_pkl)\n",
    "    print(f\"  Saved DataFrame with embeddings to: {out_pkl.name}\")\n",
    "\n",
    "print(\"\\nAll shards processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3026a-705a-44e6-98f4-9d7424bb1bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
