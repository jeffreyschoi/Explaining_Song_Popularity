{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook begins the steps for implementing the data into a RAG system. We give the LLM the user-inputed lyrics, and we then find the embedding, use FAISS to compare and grab k similar lyrics from our data, and the LLM predicts popularity and explain why given the popularity and audio features of the similar songs. \n",
    "\n",
    "There is sitll work to be done:\n",
    "\n",
    "- we use the LLM for prediciton and explinations. using a prediction model instead can lead to better reproducibility (consistant scores)\n",
    "- we currently use dummy lyric embedding and FAISS similarity functions\n",
    "- better prompting techniques\n",
    "- deep eval to evaluate the perforamnce of RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache was clean (no corrupted files found).\n",
      "Downloading model... (This will be silent, wait ~20 seconds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Model loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# --- FIX 1: Silence the Progress Bar (Aggressive Mode) ---\n",
    "# This disables ALL progress bars, which prevents the 'IProgress' crash\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\"\n",
    "\n",
    "# --- FIX 2: Delete the Corrupted Cache ---\n",
    "# We need to remove the broken download from the previous attempt\n",
    "cache_dir = Path(os.path.expanduser(\"~/.cache/huggingface/hub\"))\n",
    "model_dir = cache_dir / \"models--sentence-transformers--all-MiniLM-L6-v2\"\n",
    "\n",
    "if model_dir.exists():\n",
    "    print(f\"Removing corrupted cache at: {model_dir}\")\n",
    "    shutil.rmtree(model_dir)\n",
    "else:\n",
    "    print(\"Cache was clean (no corrupted files found).\")\n",
    "\n",
    "# --- NOW LOAD THE MODEL ---\n",
    "print(\"Downloading model... (This will be silent, wait ~20 seconds)\")\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# This should now run cleanly\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Success! Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data and making df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "pickle1 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_0_clean_ml_with_emb.pkl\")\n",
    "pickle2 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_1_clean_ml_with_emb.pkl\")\n",
    "pickle3 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_2_clean_ml_with_emb.pkl\")\n",
    "pickle4 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_3_clean_ml_with_emb.pkl\")\n",
    "pickle5 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_4_clean_ml_with_emb.pkl\")\n",
    "\n",
    "df = pd.concat([pickle1, pickle2, pickle3, pickle4, pickle5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building FAISS Index and using top 50 rows since we don't have the actual lyric embeddings yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building temporary index from top 50 songs...\n",
      "Success! Created index with 50 songs.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "print(\"Building temporary index from top 50 songs...\")\n",
    "\n",
    "# 1. Grab the top 50 rows from the dataframe\n",
    "# We use .copy() to ensure we don't affect the original dataframe\n",
    "df_subset = df.head(50).copy()\n",
    "\n",
    "# 2. Combine title + artist + lyrics for the vector\n",
    "# We handle non-string data just in case by forcing .astype(str)\n",
    "subset_text = (\n",
    "    df_subset['title'].astype(str) + \" \" +\n",
    "    df_subset['artist'].astype(str) + \" \" +\n",
    "    df_subset['lyrics'].astype(str).str.slice(0, 500)\n",
    ").tolist()\n",
    "\n",
    "# 3. Generate vectors using the model you just loaded\n",
    "subset_vectors = model.encode(subset_text)\n",
    "\n",
    "# 4. Build FAISS Index\n",
    "dimension = subset_vectors.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(subset_vectors.astype('float32'))\n",
    "\n",
    "print(f\"Success! Created index with {index.ntotal} songs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REAL embedding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "emb_list = [np.asarray(x, dtype=\"float32\") for x in df[\"lyrics_embedding\"].values]\n",
    "emb_matrix = np.stack(emb_list, axis=0)\n",
    "dimension = emb_matrix.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "index.add(emb_matrix.astype(\"float32\"))\n",
    "\n",
    "print(\"FAISS index built with\", index.ntotal, \"vectors.\")\n",
    "\n",
    "def retrieve_similar_songs(query_embedding: np.ndarray, k: int = 5) -> List[Dict[str, Any]]:\n",
    "    query_vector = np.array([query_embedding]).astype('float32')\n",
    "    D, I = index.search(query_vector, k)\n",
    "\n",
    "    neighbors = []\n",
    "    for idx, dist in zip(I[0], D[0]):\n",
    "        if idx != -1:\n",
    "            neighbors.append({\n",
    "                \"index\": int(idx),\n",
    "                \"similarity\": float(dist)\n",
    "            })\n",
    "\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>query_title</th>\n",
       "      <th>query_artist</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>popularity</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>preview_url</th>\n",
       "      <th>track_id</th>\n",
       "      <th>...</th>\n",
       "      <th>spectral_contrast_6</th>\n",
       "      <th>spectral_contrast_7</th>\n",
       "      <th>tonnetz_1</th>\n",
       "      <th>tonnetz_2</th>\n",
       "      <th>tonnetz_3</th>\n",
       "      <th>tonnetz_4</th>\n",
       "      <th>tonnetz_5</th>\n",
       "      <th>tonnetz_6</th>\n",
       "      <th>lyrics_clean</th>\n",
       "      <th>lyrics_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4845</td>\n",
       "      <td>State of Mind</td>\n",
       "      <td>Scooter</td>\n",
       "      <td>state of mind</td>\n",
       "      <td>scooter</td>\n",
       "      <td>happy</td>\n",
       "      <td>24.0</td>\n",
       "      <td>The world seems not the same...\\n\\nIntroducing...</td>\n",
       "      <td>https://audio-ssl.itunes.apple.com/itunes-asse...</td>\n",
       "      <td>1692327616</td>\n",
       "      <td>...</td>\n",
       "      <td>18.328021</td>\n",
       "      <td>39.053367</td>\n",
       "      <td>0.197966</td>\n",
       "      <td>-0.116721</td>\n",
       "      <td>0.142559</td>\n",
       "      <td>-0.069539</td>\n",
       "      <td>-0.044986</td>\n",
       "      <td>-0.047523</td>\n",
       "      <td>the world seems not the same introducing twist...</td>\n",
       "      <td>[0.07519828, -0.0233649, -0.06524662, -0.07315...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462</td>\n",
       "      <td>Reptilia</td>\n",
       "      <td>The Strokes</td>\n",
       "      <td>reptilia</td>\n",
       "      <td>the strokes</td>\n",
       "      <td>alt-rock</td>\n",
       "      <td>75.0</td>\n",
       "      <td>[Verse 1]\\nHe seemed impressed by the way you ...</td>\n",
       "      <td>https://audio-ssl.itunes.apple.com/itunes-asse...</td>\n",
       "      <td>302987569</td>\n",
       "      <td>...</td>\n",
       "      <td>17.382681</td>\n",
       "      <td>39.012014</td>\n",
       "      <td>0.078138</td>\n",
       "      <td>-0.077754</td>\n",
       "      <td>0.063345</td>\n",
       "      <td>0.036541</td>\n",
       "      <td>-0.011976</td>\n",
       "      <td>-0.014041</td>\n",
       "      <td>he seemed impressed by the way you came in tel...</td>\n",
       "      <td>[-0.08670999, -0.025700577, -0.08122497, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16017</td>\n",
       "      <td>None Of My Business</td>\n",
       "      <td>Cher Lloyd</td>\n",
       "      <td>none of my business</td>\n",
       "      <td>cher lloyd</td>\n",
       "      <td>electro</td>\n",
       "      <td>64.0</td>\n",
       "      <td>[Chorus]\\nDamn, I heard that you and her been ...</td>\n",
       "      <td>https://audio-ssl.itunes.apple.com/itunes-asse...</td>\n",
       "      <td>1438630505</td>\n",
       "      <td>...</td>\n",
       "      <td>18.248683</td>\n",
       "      <td>39.966514</td>\n",
       "      <td>0.013912</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>-0.092766</td>\n",
       "      <td>-0.056323</td>\n",
       "      <td>-0.004173</td>\n",
       "      <td>-0.014388</td>\n",
       "      <td>damn i heard that you and her been having prob...</td>\n",
       "      <td>[0.017929412, 0.0015679213, 0.00086991367, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9478</td>\n",
       "      <td>Trouble Sleeping</td>\n",
       "      <td>The Perishers</td>\n",
       "      <td>trouble sleeping</td>\n",
       "      <td>the perishers</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>48.0</td>\n",
       "      <td>I'm having trouble sleeping\\nYou're jumping in...</td>\n",
       "      <td>https://audio-ssl.itunes.apple.com/itunes-asse...</td>\n",
       "      <td>89335271</td>\n",
       "      <td>...</td>\n",
       "      <td>16.969837</td>\n",
       "      <td>28.947224</td>\n",
       "      <td>-0.118755</td>\n",
       "      <td>0.195544</td>\n",
       "      <td>0.025169</td>\n",
       "      <td>-0.130705</td>\n",
       "      <td>0.024176</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>i'm having trouble sleeping you're jumping in ...</td>\n",
       "      <td>[0.012034113, -0.0008498362, -0.040335782, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2822</td>\n",
       "      <td>Shot in the Dark</td>\n",
       "      <td>Ozzy Osbourne</td>\n",
       "      <td>shot in the dark</td>\n",
       "      <td>ozzy osbourne</td>\n",
       "      <td>hard-rock</td>\n",
       "      <td>65.0</td>\n",
       "      <td>[Verse 1]\\nOut on the streets I'm stalking the...</td>\n",
       "      <td>https://audio-ssl.itunes.apple.com/itunes-asse...</td>\n",
       "      <td>158711416</td>\n",
       "      <td>...</td>\n",
       "      <td>17.184653</td>\n",
       "      <td>35.540522</td>\n",
       "      <td>-0.113671</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>-0.029743</td>\n",
       "      <td>-0.051142</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>-0.011837</td>\n",
       "      <td>out on the streets i'm stalking the night i ca...</td>\n",
       "      <td>[-0.054401744, 0.021241566, -0.05175488, -0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id                title         artist          query_title  \\\n",
       "0     4845        State of Mind        Scooter        state of mind   \n",
       "1      462             Reptilia    The Strokes             reptilia   \n",
       "2    16017  None Of My Business     Cher Lloyd  none of my business   \n",
       "3     9478     Trouble Sleeping  The Perishers     trouble sleeping   \n",
       "4     2822     Shot in the Dark  Ozzy Osbourne     shot in the dark   \n",
       "\n",
       "    query_artist track_genre  popularity  \\\n",
       "0        scooter       happy        24.0   \n",
       "1    the strokes    alt-rock        75.0   \n",
       "2     cher lloyd     electro        64.0   \n",
       "3  the perishers    acoustic        48.0   \n",
       "4  ozzy osbourne   hard-rock        65.0   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  The world seems not the same...\\n\\nIntroducing...   \n",
       "1  [Verse 1]\\nHe seemed impressed by the way you ...   \n",
       "2  [Chorus]\\nDamn, I heard that you and her been ...   \n",
       "3  I'm having trouble sleeping\\nYou're jumping in...   \n",
       "4  [Verse 1]\\nOut on the streets I'm stalking the...   \n",
       "\n",
       "                                         preview_url    track_id  ...  \\\n",
       "0  https://audio-ssl.itunes.apple.com/itunes-asse...  1692327616  ...   \n",
       "1  https://audio-ssl.itunes.apple.com/itunes-asse...   302987569  ...   \n",
       "2  https://audio-ssl.itunes.apple.com/itunes-asse...  1438630505  ...   \n",
       "3  https://audio-ssl.itunes.apple.com/itunes-asse...    89335271  ...   \n",
       "4  https://audio-ssl.itunes.apple.com/itunes-asse...   158711416  ...   \n",
       "\n",
       "  spectral_contrast_6  spectral_contrast_7 tonnetz_1  tonnetz_2  tonnetz_3  \\\n",
       "0           18.328021            39.053367  0.197966  -0.116721   0.142559   \n",
       "1           17.382681            39.012014  0.078138  -0.077754   0.063345   \n",
       "2           18.248683            39.966514  0.013912   0.172900  -0.092766   \n",
       "3           16.969837            28.947224 -0.118755   0.195544   0.025169   \n",
       "4           17.184653            35.540522 -0.113671   0.023209  -0.029743   \n",
       "\n",
       "   tonnetz_4  tonnetz_5  tonnetz_6  \\\n",
       "0  -0.069539  -0.044986  -0.047523   \n",
       "1   0.036541  -0.011976  -0.014041   \n",
       "2  -0.056323  -0.004173  -0.014388   \n",
       "3  -0.130705   0.024176   0.005865   \n",
       "4  -0.051142   0.003486  -0.011837   \n",
       "\n",
       "                                        lyrics_clean  \\\n",
       "0  the world seems not the same introducing twist...   \n",
       "1  he seemed impressed by the way you came in tel...   \n",
       "2  damn i heard that you and her been having prob...   \n",
       "3  i'm having trouble sleeping you're jumping in ...   \n",
       "4  out on the streets i'm stalking the night i ca...   \n",
       "\n",
       "                                    lyrics_embedding  \n",
       "0  [0.07519828, -0.0233649, -0.06524662, -0.07315...  \n",
       "1  [-0.08670999, -0.025700577, -0.08122497, -0.02...  \n",
       "2  [0.017929412, 0.0015679213, 0.00086991367, -0....  \n",
       "3  [0.012034113, -0.0008498362, -0.040335782, 0.0...  \n",
       "4  [-0.054401744, 0.021241566, -0.05175488, -0.01...  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_feature_cols = list(df.columns[df.columns.get_loc(\"duration\")+1:])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_neighbors(df, query_embedding, k=5):\n",
    "    raw_neighbors = retrieve_similar_songs(query_embedding, k=k)\n",
    "    neighbors = []\n",
    "\n",
    "    for n in raw_neighbors:\n",
    "        idx = n[\"index\"]\n",
    "        row = df.iloc[idx]\n",
    "\n",
    "        audio_features = {}\n",
    "\n",
    "        for col in audio_feature_cols:\n",
    "            val = row[col]\n",
    "\n",
    "            # keep if scalar\n",
    "            if np.isscalar(val):\n",
    "                audio_features[col] = float(val)\n",
    "            \n",
    "            # flatten if array\n",
    "            elif isinstance(val, np.ndarray):\n",
    "                val = val.flatten()\n",
    "                for j, v in enumerate(val):\n",
    "                    audio_features[f\"{col}_{j}\"] = float(v)\n",
    "            \n",
    "            # flatten if list\n",
    "            elif isinstance(val, list):\n",
    "                for j, v in enumerate(val):\n",
    "                    audio_features[f\"{col}_{j}\"] = float(v)\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    audio_features[col] = float(val)\n",
    "                except Exception:\n",
    "                    audio_features[col] = None\n",
    "\n",
    "        neighbor_data = {\n",
    "            \"song_id\": row[\"song_id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"artist\": row[\"artist\"],\n",
    "            \"similarity\": n.get(\"similarity\", None),\n",
    "            \"popularity\": float(row[\"popularity\"]),\n",
    "            \"lyrics_snippet\": row[\"lyrics\"][:400].replace(\"\\n\", \" \") + \"...\",\n",
    "            \"audio_features\": audio_features\n",
    "        }\n",
    "        \n",
    "        neighbors.append(neighbor_data)\n",
    "\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue working on promping\n",
    "def build_rag_prompt_for_lyric_popularity(user_lyric: str,neighbors: List[Dict[str, Any]]) -> str:\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"You are an expert in music analytics, audio features, and lyric interpretation.\")\n",
    "    lines.append(\"You are given a NEW lyric and several similar songs from a dataset.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Each similar song includes:\")\n",
    "    lines.append(\" - song_id, title, artist\")\n",
    "    lines.append(\" - lyric snippet\")\n",
    "    lines.append(\" - popularity score (0-100)\")\n",
    "    lines.append(\" - detailed audio features extracted from 30-second clips\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Your tasks are:\")\n",
    "    lines.append(\"  1. Predict a popularity score (0-100) for the NEW lyric.\")\n",
    "    lines.append(\"  2. Explain your reasoning using comparisons to the similar songs.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Keep in mind the audio features of the similar songs, and explain what they mean in context to everyday people.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Return your answer as VALID JSON with this exact format:\")\n",
    "    lines.append(\"{\")\n",
    "    lines.append('  \"predicted_popularity\": <number>,')\n",
    "    lines.append('  \"explanation\": \"<multi-paragraph explanation grounded in the provided songs>\"')\n",
    "    lines.append(\"}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"IMPORTANT:\")\n",
    "    lines.append(\"Return ONLY raw JSON.\")\n",
    "    lines.append(\"Do NOT include any code fences such as ``` json\")\n",
    "    lines.append(\"Do NOT include any explanation text outside the JSON.\")\n",
    "    lines.append(\"Do NOT add commentary before or after the JSON.\")\n",
    "    lines.append(\"Return JSON ONLY.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\"NEW LYRIC:\")\n",
    "    lines.append(user_lyric.strip())\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"SIMILAR SONGS FROM THE DATASET (use these as evidence):\")\n",
    "\n",
    "    for i, nb in enumerate(neighbors, start=1):\n",
    "        lines.append(f\"\\nNeighbor #{i}:\")\n",
    "        lines.append(f\"  song_id: {nb['song_id']}\")\n",
    "        lines.append(f\"  title: {nb['title']}\")\n",
    "        lines.append(f\"  artist: {nb['artist']}\")\n",
    "        if nb[\"similarity\"] is not None:\n",
    "            lines.append(f\"  similarity: {nb['similarity']:.4f}\")\n",
    "        lines.append(f\"  popularity: {nb['popularity']:.2f}\")\n",
    "        lines.append(f\"  lyrics_snippet: {nb['lyrics_snippet']}\")\n",
    "        lines.append(\"  audio_features:\")\n",
    "\n",
    "        for feat_name, feat_val in nb[\"audio_features\"].items():\n",
    "            lines.append(f\"    {feat_name}: {feat_val:.4f}\")\n",
    "\n",
    "    lines.append(\"\")\n",
    "    lines.append(\n",
    "        \"Using ONLY the information above, estimate the popularity of the new lyric \"\n",
    "        \"and explain your reasoning in terms of lyric similarity, artist/genre patterns, \"\n",
    "        \"and audio features (energy, brightness, tempo, chroma, MFCCs, contrasts, tonnetz, etc.).\"\n",
    "        \"Make sure to contextulize what the audio features mean for the average person.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      7\u001b[39m load_dotenv()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "def call_llm_for_popularity_and_explanation(prompt: str) -> dict:\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=prompt,\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=900\n",
    "    )\n",
    "\n",
    "    raw_text = response.output[0].content[0].text.strip()\n",
    "\n",
    "    # Remove any ```json ...``` or ```\n",
    "    raw_text = raw_text.replace(\"```json\", \"\")\n",
    "    raw_text = raw_text.replace(\"```\", \"\")\n",
    "    raw_text = raw_text.strip()\n",
    "\n",
    "    # first try direct json parse\n",
    "    try:\n",
    "        return json.loads(raw_text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # else, find outside json block using regex\n",
    "    json_matches = re.findall(r\"\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\}\", raw_text, flags=re.DOTALL)\n",
    "\n",
    "    if json_matches:\n",
    "        for match in json_matches:\n",
    "            try:\n",
    "                return json.loads(match)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # try to repair json with trailing commas\n",
    "    repaired = re.sub(r\",\\s*([}\\]])\", r\"\\1\", raw_text)\n",
    "\n",
    "    try:\n",
    "        return json.loads(repaired)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # else, say failed\n",
    "    print(\"Could not parse JSON from LLM output. Returning raw text.\")\n",
    "    return {\n",
    "        \"predicted_popularity\": None,\n",
    "        \"explanation\": raw_text\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_lyric_popularity_system(df: pd.DataFrame, user_lyric: str, k_neighbors: int = 5) -> Dict[str, Any]:\n",
    "    # 1) embed\n",
    "    query_embedding = embed_lyrics(user_lyric)\n",
    "\n",
    "    # 2) find songs with similar sounding lyrics\n",
    "    neighbors = get_top_k_neighbors(df, query_embedding, k=k_neighbors)\n",
    "\n",
    "    # 3) build prompt\n",
    "    prompt = build_rag_prompt_for_lyric_popularity(user_lyric, neighbors)\n",
    "\n",
    "    # 4) call llm\n",
    "    llm_output = call_llm_for_popularity_and_explanation(prompt)\n",
    "\n",
    "    pred_pop = llm_output.get(\"predicted_popularity\", None)\n",
    "    explanation = llm_output.get(\"explanation\", \"\")\n",
    "\n",
    "    return {\n",
    "        \"predicted_popularity\": pred_pop,\n",
    "        \"explanation\": explanation,\n",
    "        \"neighbors_used\": neighbors,\n",
    "        \"prompt_sent\": prompt,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can test the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Grab the existing list (which currently has the bad columns)\n",
    "# Note: Ensure this variable exists. If not, re-run the cell where it was defined originally.\n",
    "# If you get a NameError here, look for the cell with 'audio_feature_cols = ...' and run it first.\n",
    "\n",
    "# 2. Filter it to keep ONLY numeric columns\n",
    "# We explicitly exclude 'lyrics', 'title', 'artist', etc. by checking the data type.\n",
    "audio_feature_cols = [\n",
    "    col for col in audio_feature_cols \n",
    "    if pd.api.types.is_numeric_dtype(df[col])\n",
    "]\n",
    "\n",
    "print(f\"Sanitized feature list. Removed non-numeric columns.\")\n",
    "print(f\"Count of valid audio features: {len(audio_feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I don't have an Open AI Key, so I built a mock LLM function. Remove to run with the Open AI cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MOCK LLM FUNCTION (No API Key Needed) ---\n",
    "# This replaces the function from the skipped cell.\n",
    "def call_llm_for_popularity_and_explanation(prompt: str) -> dict:\n",
    "    print(\" [Mock LLM] Prompt received! (Skipping OpenAI call)\")\n",
    "    \n",
    "    # Return a fake response so the pipeline doesn't crash\n",
    "    return {\n",
    "        \"predicted_popularity\": 42, # Dummy score\n",
    "        \"explanation\": (\n",
    "            \"SUCCESS: The pipeline ran successfully!\\n\"\n",
    "            \"Since you don't have an OpenAI API key, this is a placeholder explanation.\\n\"\n",
    "            \"However, the fact that you see this means your FAISS retrieval and \"\n",
    "            \"data processing steps (Step 1 & 2) are working perfectly.\"\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lyric = \"random test lyrics.\"\n",
    "result = rag_lyric_popularity_system(df, test_lyric, k_neighbors=3)\n",
    "\n",
    "print(\"Predicted popularity:\", result[\"predicted_popularity\"])\n",
    "print(\"\\nExplanation:\\n\", result[\"explanation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PRODUCTION CELL: GENERATE FULL INDEX ---\n",
    "# NOTE TO TEAM: The HPC environment runs out of memory on the full 20k dataset.\n",
    "# Please run this cell on a machine with 16GB+ RAM to generate the final files.\n",
    "\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "def generate_full_index():\n",
    "    print(\"Generating full 20k index...\")\n",
    "    \n",
    "    # 1. Prepare Data\n",
    "    full_text = (\n",
    "        df['title'].astype(str) + \" \" +\n",
    "        df['artist'].astype(str) + \" \" +\n",
    "        df['lyrics'].astype(str).str.slice(0, 500)\n",
    "    ).tolist()\n",
    "    \n",
    "    # 2. Embed (Batch processing recommended if memory is tight)\n",
    "    # Note: Using show_progress_bar=True is fine on local machines\n",
    "    full_vectors = model.encode(full_text, show_progress_bar=True)\n",
    "    \n",
    "    # 3. Build Index\n",
    "    dimension = 384\n",
    "    final_index = faiss.IndexFlatL2(dimension)\n",
    "    final_index.add(full_vectors.astype('float32'))\n",
    "    \n",
    "    # 4. Save\n",
    "    faiss.write_index(final_index, \"lyrics_20k.index\")\n",
    "    df.to_pickle(\"lyrics_20k_metadata.pkl\")\n",
    "    print(\"Files saved successfully.\")\n",
    "\n",
    "# Uncomment the line below to run generation:\n",
    "# generate_full_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
