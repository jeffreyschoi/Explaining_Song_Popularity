{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook begins the steps for implementing the data into a RAG system. We give the LLM the user-inputed lyrics, and we then find the embedding, use FAISS to compare and grab k similar lyrics from our data, and the LLM predicts popularity and explain why given the popularity and audio features of the similar songs. \n",
    "\n",
    "There is sitll work to be done:\n",
    "\n",
    "- we use the LLM for prediciton and explinations. using a prediction model instead can lead to better reproducibility (consistant scores)\n",
    "- we currently use dummy lyric embedding and FAISS similarity functions\n",
    "- better prompting techniques\n",
    "- deep eval to evaluate the perforamnce of RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# --- FIX 1: Silence the Progress Bar (Aggressive Mode) ---\n",
    "# This disables ALL progress bars, which prevents the 'IProgress' crash\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\"\n",
    "\n",
    "# --- FIX 2: Delete the Corrupted Cache ---\n",
    "# We need to remove the broken download from the previous attempt\n",
    "cache_dir = Path(os.path.expanduser(\"~/.cache/huggingface/hub\"))\n",
    "model_dir = cache_dir / \"models--sentence-transformers--all-MiniLM-L6-v2\"\n",
    "\n",
    "if model_dir.exists():\n",
    "    print(f\"Removing corrupted cache at: {model_dir}\")\n",
    "    shutil.rmtree(model_dir)\n",
    "else:\n",
    "    print(\"Cache was clean (no corrupted files found).\")\n",
    "\n",
    "# --- NOW LOAD THE MODEL ---\n",
    "print(\"Downloading model... (This will be silent, wait ~20 seconds)\")\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# This should now run cleanly\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Success! Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data and making df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "pickle1 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_0_clean_ml_with_emb.pkl\")\n",
    "pickle2 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_1_clean_ml_with_emb.pkl\")\n",
    "pickle3 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_2_clean_ml_with_emb.pkl\")\n",
    "pickle4 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_3_clean_ml_with_emb.pkl\")\n",
    "pickle5 = pd.read_pickle(\"data/lyric_embeddings/librosa_shard_4_clean_ml_with_emb.pkl\")\n",
    "\n",
    "df = pd.concat([pickle1, pickle2, pickle3, pickle4, pickle5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building FAISS Index and using top 50 rows since we don't have the actual lyric embeddings yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "print(\"Building temporary index from top 50 songs...\")\n",
    "\n",
    "# 1. Grab the top 50 rows from the dataframe\n",
    "# We use .copy() to ensure we don't affect the original dataframe\n",
    "df_subset = df.head(50).copy()\n",
    "\n",
    "# 2. Combine title + artist + lyrics for the vector\n",
    "# We handle non-string data just in case by forcing .astype(str)\n",
    "subset_text = (\n",
    "    df_subset['title'].astype(str) + \" \" +\n",
    "    df_subset['artist'].astype(str) + \" \" +\n",
    "    df_subset['lyrics'].astype(str).str.slice(0, 500)\n",
    ").tolist()\n",
    "\n",
    "# 3. Generate vectors using the model you just loaded\n",
    "subset_vectors = model.encode(subset_text)\n",
    "\n",
    "# 4. Build FAISS Index\n",
    "dimension = subset_vectors.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(subset_vectors.astype('float32'))\n",
    "\n",
    "print(f\"Success! Created index with {index.ntotal} songs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REAL embedding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "# Real embedding function\n",
    "def embed_lyrics(text: str) -> np.ndarray:\n",
    "    # 1. Encode the text using SBERT\n",
    "    vector = model.encode([text])\n",
    "    # 2. Flatten to 1D array as expected by downstream code\n",
    "    return vector[0].astype('float32')\n",
    "\n",
    "# Real FAISS retrieval function\n",
    "def retrieve_similar_songs(query_embedding: np.ndarray, k: int = 5) -> List[Dict[str, Any]]:\n",
    "    # Ensure query is 2D array (1, 384) for FAISS\n",
    "    query_vector = np.array([query_embedding]).astype('float32')\n",
    "\n",
    "    # 1. Search the index\n",
    "    # Note: We search the 'index' object we created in the previous cell\n",
    "    D, I = index.search(query_vector, k)\n",
    "\n",
    "    neighbors = []\n",
    "    # I[0] contains the IDs, D[0] contains the distances\n",
    "    for idx, dist in zip(I[0], D[0]):\n",
    "        if idx != -1:\n",
    "            neighbors.append({\n",
    "                \"index\": int(idx),\n",
    "                \"similarity\": float(dist) # In L2, lower is better.\n",
    "            })\n",
    "\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_feature_cols = list(df.columns[df.columns.get_loc(\"duration\")+1:])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_neighbors(df, query_embedding, k=5):\n",
    "    raw_neighbors = retrieve_similar_songs(query_embedding, k=k)\n",
    "    neighbors = []\n",
    "\n",
    "    for n in raw_neighbors:\n",
    "        idx = n[\"index\"]\n",
    "        row = df.iloc[idx]\n",
    "\n",
    "        audio_features = {}\n",
    "\n",
    "        for col in audio_feature_cols:\n",
    "            val = row[col]\n",
    "\n",
    "            # keep if scalar\n",
    "            if np.isscalar(val):\n",
    "                audio_features[col] = float(val)\n",
    "            \n",
    "            # flatten if array\n",
    "            elif isinstance(val, np.ndarray):\n",
    "                val = val.flatten()\n",
    "                for j, v in enumerate(val):\n",
    "                    audio_features[f\"{col}_{j}\"] = float(v)\n",
    "            \n",
    "            # flatten if list\n",
    "            elif isinstance(val, list):\n",
    "                for j, v in enumerate(val):\n",
    "                    audio_features[f\"{col}_{j}\"] = float(v)\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    audio_features[col] = float(val)\n",
    "                except Exception:\n",
    "                    audio_features[col] = None\n",
    "\n",
    "        neighbor_data = {\n",
    "            \"song_id\": row[\"song_id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"artist\": row[\"artist\"],\n",
    "            \"similarity\": n.get(\"similarity\", None),\n",
    "            \"popularity\": float(row[\"popularity\"]),\n",
    "            \"lyrics_snippet\": row[\"lyrics\"][:400].replace(\"\\n\", \" \") + \"...\",\n",
    "            \"audio_features\": audio_features\n",
    "        }\n",
    "        \n",
    "        neighbors.append(neighbor_data)\n",
    "\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue working on promping\n",
    "def build_rag_prompt_for_lyric_popularity(user_lyric: str,neighbors: List[Dict[str, Any]]) -> str:\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"You are an expert in music analytics, audio features, and lyric interpretation.\")\n",
    "    lines.append(\"You are given a NEW lyric and several similar songs from a dataset.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Each similar song includes:\")\n",
    "    lines.append(\" - song_id, title, artist\")\n",
    "    lines.append(\" - lyric snippet\")\n",
    "    lines.append(\" - popularity score (0-100)\")\n",
    "    lines.append(\" - detailed audio features extracted from 30-second clips\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Your tasks are:\")\n",
    "    lines.append(\"  1. Predict a popularity score (0-100) for the NEW lyric.\")\n",
    "    lines.append(\"  2. Explain your reasoning using comparisons to the similar songs.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Keep in mind the audio features of the similar songs, and explain what they mean in context to everyday people.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Return your answer as VALID JSON with this exact format:\")\n",
    "    lines.append(\"{\")\n",
    "    lines.append('  \"predicted_popularity\": <number>,')\n",
    "    lines.append('  \"explanation\": \"<multi-paragraph explanation grounded in the provided songs>\"')\n",
    "    lines.append(\"}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"IMPORTANT:\")\n",
    "    lines.append(\"Return ONLY raw JSON.\")\n",
    "    lines.append(\"Do NOT include any code fences such as ``` json\")\n",
    "    lines.append(\"Do NOT include any explanation text outside the JSON.\")\n",
    "    lines.append(\"Do NOT add commentary before or after the JSON.\")\n",
    "    lines.append(\"Return JSON ONLY.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\"NEW LYRIC:\")\n",
    "    lines.append(user_lyric.strip())\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"SIMILAR SONGS FROM THE DATASET (use these as evidence):\")\n",
    "\n",
    "    for i, nb in enumerate(neighbors, start=1):\n",
    "        lines.append(f\"\\nNeighbor #{i}:\")\n",
    "        lines.append(f\"  song_id: {nb['song_id']}\")\n",
    "        lines.append(f\"  title: {nb['title']}\")\n",
    "        lines.append(f\"  artist: {nb['artist']}\")\n",
    "        if nb[\"similarity\"] is not None:\n",
    "            lines.append(f\"  similarity: {nb['similarity']:.4f}\")\n",
    "        lines.append(f\"  popularity: {nb['popularity']:.2f}\")\n",
    "        lines.append(f\"  lyrics_snippet: {nb['lyrics_snippet']}\")\n",
    "        lines.append(\"  audio_features:\")\n",
    "\n",
    "        for feat_name, feat_val in nb[\"audio_features\"].items():\n",
    "            lines.append(f\"    {feat_name}: {feat_val:.4f}\")\n",
    "\n",
    "    lines.append(\"\")\n",
    "    lines.append(\n",
    "        \"Using ONLY the information above, estimate the popularity of the new lyric \"\n",
    "        \"and explain your reasoning in terms of lyric similarity, artist/genre patterns, \"\n",
    "        \"and audio features (energy, brightness, tempo, chroma, MFCCs, contrasts, tonnetz, etc.).\"\n",
    "        \"Make sure to contextulize what the audio features mean for the average person.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "def call_llm_for_popularity_and_explanation(prompt: str) -> dict:\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=prompt,\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=900\n",
    "    )\n",
    "\n",
    "    raw_text = response.output[0].content[0].text.strip()\n",
    "\n",
    "    # Remove any ```json ...``` or ```\n",
    "    raw_text = raw_text.replace(\"```json\", \"\")\n",
    "    raw_text = raw_text.replace(\"```\", \"\")\n",
    "    raw_text = raw_text.strip()\n",
    "\n",
    "    # first try direct json parse\n",
    "    try:\n",
    "        return json.loads(raw_text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # else, find outside json block using regex\n",
    "    json_matches = re.findall(r\"\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\}\", raw_text, flags=re.DOTALL)\n",
    "\n",
    "    if json_matches:\n",
    "        for match in json_matches:\n",
    "            try:\n",
    "                return json.loads(match)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # try to repair json with trailing commas\n",
    "    repaired = re.sub(r\",\\s*([}\\]])\", r\"\\1\", raw_text)\n",
    "\n",
    "    try:\n",
    "        return json.loads(repaired)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # else, say failed\n",
    "    print(\"Could not parse JSON from LLM output. Returning raw text.\")\n",
    "    return {\n",
    "        \"predicted_popularity\": None,\n",
    "        \"explanation\": raw_text\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_lyric_popularity_system(df: pd.DataFrame, user_lyric: str, k_neighbors: int = 5) -> Dict[str, Any]:\n",
    "    # 1) embed\n",
    "    query_embedding = embed_lyrics(user_lyric)\n",
    "\n",
    "    # 2) find songs with similar sounding lyrics\n",
    "    neighbors = get_top_k_neighbors(df, query_embedding, k=k_neighbors)\n",
    "\n",
    "    # 3) build prompt\n",
    "    prompt = build_rag_prompt_for_lyric_popularity(user_lyric, neighbors)\n",
    "\n",
    "    # 4) call llm\n",
    "    llm_output = call_llm_for_popularity_and_explanation(prompt)\n",
    "\n",
    "    pred_pop = llm_output.get(\"predicted_popularity\", None)\n",
    "    explanation = llm_output.get(\"explanation\", \"\")\n",
    "\n",
    "    return {\n",
    "        \"predicted_popularity\": pred_pop,\n",
    "        \"explanation\": explanation,\n",
    "        \"neighbors_used\": neighbors,\n",
    "        \"prompt_sent\": prompt,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can test the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Grab the existing list (which currently has the bad columns)\n",
    "# Note: Ensure this variable exists. If not, re-run the cell where it was defined originally.\n",
    "# If you get a NameError here, look for the cell with 'audio_feature_cols = ...' and run it first.\n",
    "\n",
    "# 2. Filter it to keep ONLY numeric columns\n",
    "# We explicitly exclude 'lyrics', 'title', 'artist', etc. by checking the data type.\n",
    "audio_feature_cols = [\n",
    "    col for col in audio_feature_cols \n",
    "    if pd.api.types.is_numeric_dtype(df[col])\n",
    "]\n",
    "\n",
    "print(f\"Sanitized feature list. Removed non-numeric columns.\")\n",
    "print(f\"Count of valid audio features: {len(audio_feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I don't have an Open AI Key, so I built a mock LLM function. Remove to run with the Open AI cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MOCK LLM FUNCTION (No API Key Needed) ---\n",
    "# This replaces the function from the skipped cell.\n",
    "def call_llm_for_popularity_and_explanation(prompt: str) -> dict:\n",
    "    print(\" [Mock LLM] Prompt received! (Skipping OpenAI call)\")\n",
    "    \n",
    "    # Return a fake response so the pipeline doesn't crash\n",
    "    return {\n",
    "        \"predicted_popularity\": 42, # Dummy score\n",
    "        \"explanation\": (\n",
    "            \"SUCCESS: The pipeline ran successfully!\\n\"\n",
    "            \"Since you don't have an OpenAI API key, this is a placeholder explanation.\\n\"\n",
    "            \"However, the fact that you see this means your FAISS retrieval and \"\n",
    "            \"data processing steps (Step 1 & 2) are working perfectly.\"\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lyric = \"random test lyrics.\"\n",
    "result = rag_lyric_popularity_system(df, test_lyric, k_neighbors=3)\n",
    "\n",
    "print(\"Predicted popularity:\", result[\"predicted_popularity\"])\n",
    "print(\"\\nExplanation:\\n\", result[\"explanation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PRODUCTION CELL: GENERATE FULL INDEX ---\n",
    "# NOTE TO TEAM: The HPC environment runs out of memory on the full 20k dataset.\n",
    "# Please run this cell on a machine with 16GB+ RAM to generate the final files.\n",
    "\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "def generate_full_index():\n",
    "    print(\"Generating full 20k index...\")\n",
    "    \n",
    "    # 1. Prepare Data\n",
    "    full_text = (\n",
    "        df['title'].astype(str) + \" \" +\n",
    "        df['artist'].astype(str) + \" \" +\n",
    "        df['lyrics'].astype(str).str.slice(0, 500)\n",
    "    ).tolist()\n",
    "    \n",
    "    # 2. Embed (Batch processing recommended if memory is tight)\n",
    "    # Note: Using show_progress_bar=True is fine on local machines\n",
    "    full_vectors = model.encode(full_text, show_progress_bar=True)\n",
    "    \n",
    "    # 3. Build Index\n",
    "    dimension = 384\n",
    "    final_index = faiss.IndexFlatL2(dimension)\n",
    "    final_index.add(full_vectors.astype('float32'))\n",
    "    \n",
    "    # 4. Save\n",
    "    faiss.write_index(final_index, \"lyrics_20k.index\")\n",
    "    df.to_pickle(\"lyrics_20k_metadata.pkl\")\n",
    "    print(\"Files saved successfully.\")\n",
    "\n",
    "# Uncomment the line below to run generation:\n",
    "# generate_full_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
