{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook continued off of rough_rag, and implements a prediction model for populairty prediction. The model uses the target lyric embeddings, plus the embeddings, popularity, and librosa collect audio features of its three nearest embedding neighbors by FAISS similarity search. We also use SHAP to reveal the impact of certain features for each prediction, and adding it to our retreval content for our llm to better explain.\n",
    "\n",
    "There is sitll work to be done:\n",
    "\n",
    "- we dont test the LightBGM model or show performace. we should review its accuracy and other metrics for justifiability\n",
    "- we edited the prompt for new context, also added parts to not mention the limitations of a lyric-only prediction for popularity. work can still be done\n",
    "- we also need to include song level meta data (genre, year, other things)\n",
    "- deep eval to evaluate the perforamnce of RAG\n",
    "- maybe the llm can become a critiquer over an explainer. reprompt in order to get suggetions and reflect the results of our methods for prediction popularity\n",
    "    - this would require the llm to better learn how to make the lyrics better (llm could also give counterfactual lyrics, generating better lyrics that do actually increase popularity)\n",
    "- other future work involve allowing the llm to generate counterfactual explanations, include average popularity of neighbors, similarity-weighted popularity, and variance of neighbor popularity in prediction, SHAP visualizations, streamlit ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, certifi\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import tqdm as tqdm\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data and making df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "df1 = pd.read_parquet(\"lyric_embeddings/librosa_shard_0.parquet\")\n",
    "df2 = pd.read_parquet(\"lyric_embeddings/librosa_shard_1.parquet\")\n",
    "df3 = pd.read_parquet(\"lyric_embeddings/librosa_shard_2.parquet\")\n",
    "df4 = pd.read_parquet(\"lyric_embeddings/librosa_shard_3.parquet\")\n",
    "df5 = pd.read_parquet(\"lyric_embeddings/librosa_shard_4.parquet\")\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REAL embedding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built with 20740 vectors.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "emb_list = [np.asarray(x, dtype=\"float32\") for x in df[\"lyrics_embedding\"].values]\n",
    "emb_matrix = np.stack(emb_list, axis=0)\n",
    "dimension = emb_matrix.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "index.add(emb_matrix.astype(\"float32\"))\n",
    "\n",
    "print(\"FAISS index built with\", index.ntotal, \"vectors.\")\n",
    "\n",
    "def retrieve_similar_songs(query_embedding: np.ndarray, k: int = 5) -> List[Dict[str, Any]]:\n",
    "    query_vector = np.array([query_embedding]).astype('float32')\n",
    "    D, I = index.search(query_vector, k)\n",
    "\n",
    "    neighbors = []\n",
    "    for idx, dist in zip(I[0], D[0]):\n",
    "        if idx != -1:\n",
    "            neighbors.append({\n",
    "                \"index\": int(idx),\n",
    "                \"similarity\": float(dist)\n",
    "            })\n",
    "\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def clean_lyrics_for_query(text: str) -> str:\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove headers like [chorus], [verse 1], etc.\n",
    "    text = re.sub(r\"\\[.*?\\]\", \" \", text)\n",
    "\n",
    "    # handle real and escaped newlines\n",
    "    text = text.replace(\"\\\\n\", \" \").replace(\"\\n\", \" \")\n",
    "\n",
    "    # remove (prod. ...), (remix ...)\n",
    "    text = re.sub(r\"\\(.*?prod.*?\\)\", \" \", text)\n",
    "    text = re.sub(r\"\\(.*?remix.*?\\)\", \" \", text)\n",
    "\n",
    "    # remove x2, x3, etc.\n",
    "    text = re.sub(r\"\\bx\\d+\\b\", \" \", text)\n",
    "\n",
    "    # keep letters (any language), numbers, spaces, apostrophes\n",
    "    chars = []\n",
    "    for ch in text:\n",
    "        cat = unicodedata.category(ch)\n",
    "        if cat.startswith(\"L\") or cat.startswith(\"N\") or ch in [\" \", \"'\", \"’\"]:\n",
    "            chars.append(ch)\n",
    "\n",
    "    text = \"\".join(chars)\n",
    "\n",
    "    # collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def embed_lyrics(text: str) -> np.ndarray:\n",
    "    cleaned = clean_lyrics_for_query(text)\n",
    "    emb = model.encode(\n",
    "        [cleaned],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "\n",
    "    vec = emb[0]\n",
    "\n",
    "    vec = np.asarray(vec, dtype=\"float32\").reshape(-1)\n",
    "\n",
    "    return vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>query_title</th>\n",
       "      <th>query_artist</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>popularity</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>preview_url</th>\n",
       "      <th>track_id</th>\n",
       "      <th>...</th>\n",
       "      <th>spectral_contrast_6</th>\n",
       "      <th>spectral_contrast_7</th>\n",
       "      <th>tonnetz_1</th>\n",
       "      <th>tonnetz_2</th>\n",
       "      <th>tonnetz_3</th>\n",
       "      <th>tonnetz_4</th>\n",
       "      <th>tonnetz_5</th>\n",
       "      <th>tonnetz_6</th>\n",
       "      <th>lyrics_clean</th>\n",
       "      <th>lyrics_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4845</td>\n",
       "      <td>State of Mind</td>\n",
       "      <td>Scooter</td>\n",
       "      <td>state of mind</td>\n",
       "      <td>scooter</td>\n",
       "      <td>happy</td>\n",
       "      <td>24.0</td>\n",
       "      <td>The world seems not the same...\\n\\nIntroducing...</td>\n",
       "      <td>https://audio-ssl.itunes.apple.com/itunes-asse...</td>\n",
       "      <td>1692327616</td>\n",
       "      <td>...</td>\n",
       "      <td>18.328021</td>\n",
       "      <td>39.053367</td>\n",
       "      <td>0.197966</td>\n",
       "      <td>-0.116721</td>\n",
       "      <td>0.142559</td>\n",
       "      <td>-0.069539</td>\n",
       "      <td>-0.044986</td>\n",
       "      <td>-0.047523</td>\n",
       "      <td>the world seems not the same introducing twist...</td>\n",
       "      <td>[0.07519827783107758, -0.023364899680018425, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462</td>\n",
       "      <td>Reptilia</td>\n",
       "      <td>The Strokes</td>\n",
       "      <td>reptilia</td>\n",
       "      <td>the strokes</td>\n",
       "      <td>alt-rock</td>\n",
       "      <td>75.0</td>\n",
       "      <td>[Verse 1]\\nHe seemed impressed by the way you ...</td>\n",
       "      <td>https://audio-ssl.itunes.apple.com/itunes-asse...</td>\n",
       "      <td>302987569</td>\n",
       "      <td>...</td>\n",
       "      <td>17.382681</td>\n",
       "      <td>39.012014</td>\n",
       "      <td>0.078138</td>\n",
       "      <td>-0.077754</td>\n",
       "      <td>0.063345</td>\n",
       "      <td>0.036541</td>\n",
       "      <td>-0.011976</td>\n",
       "      <td>-0.014041</td>\n",
       "      <td>he seemed impressed by the way you came in tel...</td>\n",
       "      <td>[-0.08670999109745026, -0.025700576603412628, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16017</td>\n",
       "      <td>None Of My Business</td>\n",
       "      <td>Cher Lloyd</td>\n",
       "      <td>none of my business</td>\n",
       "      <td>cher lloyd</td>\n",
       "      <td>electro</td>\n",
       "      <td>64.0</td>\n",
       "      <td>[Chorus]\\nDamn, I heard that you and her been ...</td>\n",
       "      <td>https://audio-ssl.itunes.apple.com/itunes-asse...</td>\n",
       "      <td>1438630505</td>\n",
       "      <td>...</td>\n",
       "      <td>18.248683</td>\n",
       "      <td>39.966514</td>\n",
       "      <td>0.013912</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>-0.092766</td>\n",
       "      <td>-0.056323</td>\n",
       "      <td>-0.004173</td>\n",
       "      <td>-0.014388</td>\n",
       "      <td>damn i heard that you and her been having prob...</td>\n",
       "      <td>[0.01792941242456436, 0.001567921251989901, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9478</td>\n",
       "      <td>Trouble Sleeping</td>\n",
       "      <td>The Perishers</td>\n",
       "      <td>trouble sleeping</td>\n",
       "      <td>the perishers</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>48.0</td>\n",
       "      <td>I'm having trouble sleeping\\nYou're jumping in...</td>\n",
       "      <td>https://audio-ssl.itunes.apple.com/itunes-asse...</td>\n",
       "      <td>89335271</td>\n",
       "      <td>...</td>\n",
       "      <td>16.969837</td>\n",
       "      <td>28.947224</td>\n",
       "      <td>-0.118755</td>\n",
       "      <td>0.195544</td>\n",
       "      <td>0.025169</td>\n",
       "      <td>-0.130705</td>\n",
       "      <td>0.024176</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>i'm having trouble sleeping you're jumping in ...</td>\n",
       "      <td>[0.012034112587571144, -0.0008498362149111927,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2822</td>\n",
       "      <td>Shot in the Dark</td>\n",
       "      <td>Ozzy Osbourne</td>\n",
       "      <td>shot in the dark</td>\n",
       "      <td>ozzy osbourne</td>\n",
       "      <td>hard-rock</td>\n",
       "      <td>65.0</td>\n",
       "      <td>[Verse 1]\\nOut on the streets I'm stalking the...</td>\n",
       "      <td>https://audio-ssl.itunes.apple.com/itunes-asse...</td>\n",
       "      <td>158711416</td>\n",
       "      <td>...</td>\n",
       "      <td>17.184653</td>\n",
       "      <td>35.540522</td>\n",
       "      <td>-0.113671</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>-0.029743</td>\n",
       "      <td>-0.051142</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>-0.011837</td>\n",
       "      <td>out on the streets i'm stalking the night i ca...</td>\n",
       "      <td>[-0.05440174415707588, 0.0212415661662817, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id                title         artist          query_title  \\\n",
       "0     4845        State of Mind        Scooter        state of mind   \n",
       "1      462             Reptilia    The Strokes             reptilia   \n",
       "2    16017  None Of My Business     Cher Lloyd  none of my business   \n",
       "3     9478     Trouble Sleeping  The Perishers     trouble sleeping   \n",
       "4     2822     Shot in the Dark  Ozzy Osbourne     shot in the dark   \n",
       "\n",
       "    query_artist track_genre  popularity  \\\n",
       "0        scooter       happy        24.0   \n",
       "1    the strokes    alt-rock        75.0   \n",
       "2     cher lloyd     electro        64.0   \n",
       "3  the perishers    acoustic        48.0   \n",
       "4  ozzy osbourne   hard-rock        65.0   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  The world seems not the same...\\n\\nIntroducing...   \n",
       "1  [Verse 1]\\nHe seemed impressed by the way you ...   \n",
       "2  [Chorus]\\nDamn, I heard that you and her been ...   \n",
       "3  I'm having trouble sleeping\\nYou're jumping in...   \n",
       "4  [Verse 1]\\nOut on the streets I'm stalking the...   \n",
       "\n",
       "                                         preview_url    track_id  ...  \\\n",
       "0  https://audio-ssl.itunes.apple.com/itunes-asse...  1692327616  ...   \n",
       "1  https://audio-ssl.itunes.apple.com/itunes-asse...   302987569  ...   \n",
       "2  https://audio-ssl.itunes.apple.com/itunes-asse...  1438630505  ...   \n",
       "3  https://audio-ssl.itunes.apple.com/itunes-asse...    89335271  ...   \n",
       "4  https://audio-ssl.itunes.apple.com/itunes-asse...   158711416  ...   \n",
       "\n",
       "  spectral_contrast_6  spectral_contrast_7 tonnetz_1  tonnetz_2  tonnetz_3  \\\n",
       "0           18.328021            39.053367  0.197966  -0.116721   0.142559   \n",
       "1           17.382681            39.012014  0.078138  -0.077754   0.063345   \n",
       "2           18.248683            39.966514  0.013912   0.172900  -0.092766   \n",
       "3           16.969837            28.947224 -0.118755   0.195544   0.025169   \n",
       "4           17.184653            35.540522 -0.113671   0.023209  -0.029743   \n",
       "\n",
       "   tonnetz_4  tonnetz_5  tonnetz_6  \\\n",
       "0  -0.069539  -0.044986  -0.047523   \n",
       "1   0.036541  -0.011976  -0.014041   \n",
       "2  -0.056323  -0.004173  -0.014388   \n",
       "3  -0.130705   0.024176   0.005865   \n",
       "4  -0.051142   0.003486  -0.011837   \n",
       "\n",
       "                                        lyrics_clean  \\\n",
       "0  the world seems not the same introducing twist...   \n",
       "1  he seemed impressed by the way you came in tel...   \n",
       "2  damn i heard that you and her been having prob...   \n",
       "3  i'm having trouble sleeping you're jumping in ...   \n",
       "4  out on the streets i'm stalking the night i ca...   \n",
       "\n",
       "                                    lyrics_embedding  \n",
       "0  [0.07519827783107758, -0.023364899680018425, -...  \n",
       "1  [-0.08670999109745026, -0.025700576603412628, ...  \n",
       "2  [0.01792941242456436, 0.001567921251989901, 0....  \n",
       "3  [0.012034112587571144, -0.0008498362149111927,...  \n",
       "4  [-0.05440174415707588, 0.0212415661662817, -0....  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_feature_cols = df.columns[df.columns.get_loc(\"duration\") : df.columns.get_loc(\"tonnetz_6\") + 1].tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_feature_vector(\n",
    "    target_embedding: np.ndarray,\n",
    "    neighbors: List[Dict[str, Any]],\n",
    "    audio_feature_cols: List[str],\n",
    "    k: int = 3\n",
    ") -> np.ndarray:\n",
    "\n",
    "    vec = []\n",
    "\n",
    "    target_embedding = np.asarray(target_embedding, dtype=\"float32\").reshape(-1)\n",
    "    EMB_DIM = target_embedding.shape[0]\n",
    "    vec.extend(target_embedding.tolist())\n",
    "\n",
    "    AUDIO_DIM = len(audio_feature_cols)\n",
    "    NEIGHBOR_BLOCK = EMB_DIM + 2 + AUDIO_DIM  # emb + similarity + popularity + audio to ensure they all the same size\n",
    "\n",
    "    for i in range(k):\n",
    "        if i < len(neighbors):\n",
    "            nb = neighbors[i]\n",
    "\n",
    "            # neighbor embedding\n",
    "            nb_emb = df.iloc[nb[\"index\"]][\"lyrics_embedding\"]\n",
    "            nb_emb = np.asarray(nb_emb, dtype=\"float32\").reshape(-1)\n",
    "\n",
    "            # fill nans if neighbros dont exist\n",
    "            if nb_emb.shape[0] != EMB_DIM:\n",
    "                fixed_emb = np.full(EMB_DIM, np.nan, dtype=\"float32\")\n",
    "                fixed_emb[:min(EMB_DIM, len(nb_emb))] = nb_emb[:EMB_DIM]\n",
    "                nb_emb = fixed_emb\n",
    "\n",
    "            vec.extend(nb_emb.tolist())\n",
    "\n",
    "            # similarity\n",
    "            sim = nb.get(\"similarity\", np.nan)\n",
    "            vec.append(float(sim))\n",
    "\n",
    "            # popularity\n",
    "            vec.append(float(nb[\"popularity\"]))\n",
    "\n",
    "            # audio features\n",
    "            af = nb[\"audio_features\"]\n",
    "            for col in audio_feature_cols:\n",
    "                val = af.get(col, np.nan)\n",
    "                if isinstance(val, (float, int, np.floating)):\n",
    "                    vec.append(float(val))\n",
    "                else:\n",
    "                    vec.append(np.nan)\n",
    "\n",
    "        else:\n",
    "            vec.extend([np.nan] * NEIGHBOR_BLOCK)\n",
    "\n",
    "    return np.asarray(vec, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_neighbors(df, query_embedding, k=5):\n",
    "    raw_neighbors = retrieve_similar_songs(query_embedding, k=k)\n",
    "    neighbors = []\n",
    "\n",
    "    for n in raw_neighbors:\n",
    "        idx = n[\"index\"]\n",
    "        row = df.iloc[idx]\n",
    "\n",
    "        audio_features = {}\n",
    "\n",
    "        for col in audio_feature_cols:\n",
    "            val = row[col]\n",
    "\n",
    "            # keep if scalar\n",
    "            if np.isscalar(val):\n",
    "                audio_features[col] = float(val)\n",
    "            \n",
    "            # flatten if array\n",
    "            elif isinstance(val, np.ndarray):\n",
    "                val = val.flatten()\n",
    "                for j, v in enumerate(val):\n",
    "                    audio_features[f\"{col}_{j}\"] = float(v)\n",
    "            \n",
    "            # flatten if list\n",
    "            elif isinstance(val, list):\n",
    "                for j, v in enumerate(val):\n",
    "                    audio_features[f\"{col}_{j}\"] = float(v)\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    audio_features[col] = float(val)\n",
    "                except Exception:\n",
    "                    audio_features[col] = None\n",
    "\n",
    "        neighbor_data = {\n",
    "            \"index\": idx,\n",
    "            \"song_id\": row[\"song_id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "            \"artist\": row[\"artist\"],\n",
    "            \"similarity\": n.get(\"similarity\", None),\n",
    "            \"popularity\": float(row[\"popularity\"]),\n",
    "            \"lyrics_snippet\": row[\"lyrics\"][:400].replace(\"\\n\", \" \") + \"...\",\n",
    "            \"audio_features\": audio_features\n",
    "        }\n",
    "        \n",
    "        neighbors.append(neighbor_data)\n",
    "\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    target_lyric = row[\"lyrics\"]\n",
    "    target_embedding = np.asarray(row[\"lyrics_embedding\"], dtype=\"float32\")\n",
    "\n",
    "    neighbors = get_top_k_neighbors(df, target_embedding, k=3)\n",
    "\n",
    "    x_vec = construct_feature_vector(target_embedding, neighbors, audio_feature_cols, k=3)\n",
    "\n",
    "    X.append(x_vec)\n",
    "    y.append(row[\"popularity\"])\n",
    "\n",
    "X = np.vstack(X)\n",
    "y = np.array(y, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.444943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 584457\n",
      "[LightGBM] [Info] Number of data points in the train set: 20740, number of used features: 2299\n",
      "[LightGBM] [Info] Start training from score 38.835680\n",
      "LightGBM model trained!\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_data = lgb.Dataset(X, label=y)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": [\"rmse\", \"mae\"],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 63,\n",
    "    \"max_depth\": -1,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "}\n",
    "\n",
    "model_lgb = lgb.train(params, train_data, num_boost_round=500)\n",
    "\n",
    "print(\"LightGBM model trained!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model_lgb)\n",
    "shap_values = explainer.shap_values(x_vec.reshape(1, -1))\n",
    "\n",
    "def summarize_shap_for_sample(\n",
    "    shap_values: np.ndarray,\n",
    "    feature_names: List[str] = None,\n",
    "    top_n: int = 15\n",
    ") -> List[Dict[str, Any]]:\n",
    "\n",
    "    if shap_values.ndim == 2:\n",
    "        shap_vals = shap_values[0]\n",
    "    else:\n",
    "        shap_vals = shap_values\n",
    "\n",
    "    abs_vals = np.abs(shap_vals)\n",
    "    top_idx = np.argsort(abs_vals)[::-1][:top_n]\n",
    "\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"feature_{i}\" for i in range(len(shap_vals))]\n",
    "\n",
    "    summary = []\n",
    "    for idx in top_idx:\n",
    "        summary.append({\n",
    "            \"feature\": feature_names[idx],\n",
    "            \"shap_value\": float(shap_vals[idx])\n",
    "        })\n",
    "    return summary\n",
    "\n",
    "\n",
    "def group_shap_fully(\n",
    "    shap_vals: np.ndarray,\n",
    "    EMB_DIM: int,\n",
    "    audio_feature_cols: List[str],\n",
    "    k_neighbors: int = 3\n",
    "):\n",
    "\n",
    "    if shap_vals.ndim == 2:\n",
    "        shap_vals = shap_vals[0]\n",
    "\n",
    "    idx = 0\n",
    "    groups = {}\n",
    "\n",
    "    AUDIO_DIM = len(audio_feature_cols)\n",
    "\n",
    "    target_emb_shap = shap_vals[idx : idx + EMB_DIM]\n",
    "    groups[\"target_embedding\"] = float(np.sum(target_emb_shap))\n",
    "    idx += EMB_DIM\n",
    "\n",
    "    groups[\"neighbors\"] = []\n",
    "\n",
    "    for nb in range(k_neighbors):\n",
    "\n",
    "        # group by embeddings\n",
    "        emb_block = shap_vals[idx : idx + EMB_DIM]\n",
    "        emb_sum = float(np.sum(emb_block))\n",
    "        idx += EMB_DIM\n",
    "\n",
    "        # group by similarity\n",
    "        sim_shap = float(shap_vals[idx])\n",
    "        idx += 1\n",
    "\n",
    "        # group by popularity\n",
    "        pop_shap = float(shap_vals[idx])\n",
    "        idx += 1\n",
    "\n",
    "        # dont group by audio features\n",
    "        audio_block = shap_vals[idx : idx + AUDIO_DIM]\n",
    "        idx += AUDIO_DIM\n",
    "        \n",
    "        audio_dict = {\n",
    "            feature_name: float(audio_block[j])\n",
    "            for j, feature_name in enumerate(audio_feature_cols)\n",
    "        }\n",
    "\n",
    "        groups[\"neighbors\"].append({\n",
    "            \"embedding\": emb_sum,\n",
    "            \"similarity\": sim_shap,\n",
    "            \"popularity\": pop_shap,\n",
    "            \"audio_features\": audio_dict\n",
    "        })\n",
    "\n",
    "    return groups\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue working on promping\n",
    "def build_rag_prompt_for_lyric_popularity(\n",
    "    user_lyric: str,\n",
    "    neighbors: List[Dict[str, Any]],\n",
    "    predicted_popularity: float,\n",
    "    shap_summary: List[Dict[str, Any]]\n",
    "):\n",
    "\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"You are an expert in music analytics, audio features, and lyric interpretation.\")\n",
    "    lines.append(\"Your task is to EXPLAIN a predicted popularity score for a NEW lyric.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"CRITICAL INSTRUCTIONS:\")\n",
    "    lines.append(\" - DO NOT provide disclaimers about limitations of predicting popularity from lyrics.\")\n",
    "    lines.append(\" - Ground every part of your explanation in the retrieved similar songs.\")\n",
    "    lines.append(\" - Quote specific phrases from the neighbor lyrics when helpful.\")\n",
    "    lines.append(\" - Explain audio features in simple, everyday terms.\")\n",
    "    lines.append(\" - Use the SHAP feature-attribution summary as evidence for WHY the model made its prediction.\")\n",
    "    lines.append(\" - Structure your explanation into multiple paragraphs:\")\n",
    "    lines.append(\"      Paragraph 1: Lyric similarity analysis using retrieved neighbors.\")\n",
    "    lines.append(\"      Paragraph 2: Audio feature comparisons (brightness, timbre, tempo, etc.).\")\n",
    "    lines.append(\"      Paragraph 3: Interpretation of SHAP results for this specific lyric.\")\n",
    "    lines.append(\"      Paragraph 4: Final justification tying all evidence together.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Return ONLY valid JSON with this format:\")\n",
    "    lines.append(\"{\")\n",
    "    lines.append('  \"predicted_popularity\": <number>,')\n",
    "    lines.append('  \"explanation\": \"<multi-paragraph explanation grounded in evidence>\"')\n",
    "    lines.append(\"}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"IMPORTANT:\")\n",
    "    lines.append(\"Return ONLY raw JSON.\")\n",
    "    lines.append(\"Do NOT include any code fences such as ``` json\")\n",
    "    lines.append(\"Do NOT include any explanation text outside the JSON.\")\n",
    "    lines.append(\"Do NOT add commentary before or after the JSON.\")\n",
    "    lines.append(\"Return JSON ONLY.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\"NEW LYRIC:\")\n",
    "    lines.append(user_lyric.strip())\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"Predicted Popularity Score: {predicted_popularity:.2f}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\"SHAP FEATURE-ATTRIBUTION SUMMARY (TOP CONTRIBUTORS):\")\n",
    "    lines.append(\"These features influenced the model's prediction and should be used in the explanation:\")\n",
    "    lines.append(\"SHAP FEATURE ATTRIBUTION SUMMARY (GROUPED):\")\n",
    "    lines.append(f\"  Target embedding contribution: {shap_summary['target_embedding']:+.3f}\")\n",
    "\n",
    "    lines.append(\"\\nNeighbor Contributions:\")\n",
    "    for i, nb in enumerate(shap_summary[\"neighbors\"], start=1):\n",
    "        lines.append(f\"  Neighbor {i}:\")\n",
    "        lines.append(f\"    embedding: {nb['embedding']:+.3f}\")\n",
    "        lines.append(f\"    similarity: {nb['similarity']:+.3f}\")\n",
    "        lines.append(f\"    popularity: {nb['popularity']:+.3f}\")\n",
    "        lines.append(\"    audio_features:\")\n",
    "        for feat_name, val in nb[\"audio_features\"].items():\n",
    "            lines.append(f\"      {feat_name}: {val:+.3f}\")\n",
    "\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"SIMILAR SONGS RETRIEVED FROM THE DATASET:\")\n",
    "    lines.append(\"Use these songs as evidence for lyrical themes, audio patterns, and overall justification.\")\n",
    "\n",
    "    for i, nb in enumerate(neighbors, start=1):\n",
    "        lines.append(f\"\\nNeighbor #{i}:\")\n",
    "        lines.append(f\"  song_id: {nb['song_id']}\")\n",
    "        lines.append(f\"  title: {nb['title']}\")\n",
    "        lines.append(f\"  artist: {nb['artist']}\")\n",
    "        if nb.get(\"similarity\") is not None:\n",
    "            lines.append(f\"  similarity_score: {nb['similarity']:.4f}  (lower = more similar lyrics)\")\n",
    "        lines.append(f\"  popularity: {nb['popularity']:.2f}\")\n",
    "        lines.append(f\"  lyrics_snippet: {nb['lyrics_snippet']}\")\n",
    "        lines.append(\"  audio_features:\")\n",
    "        for feat_name, feat_val in nb[\"audio_features\"].items():\n",
    "            if isinstance(feat_val, (int, float)):\n",
    "                lines.append(f\"    {feat_name}: {feat_val:.4f}\")\n",
    "            else:\n",
    "                lines.append(f\"    {feat_name}: {feat_val}\")\n",
    "\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"------------------------------------------------------------\")\n",
    "    lines.append(\n",
    "        \"Using ONLY the information above — the new lyric, retrieved neighbors, \"\n",
    "        \"the predicted popularity score, and the SHAP feature-attribution summary — \"\n",
    "        \"produce a multi-paragraph explanation grounded in the dataset evidence. \"\n",
    "        \"Do not speculate beyond what is shown. Do not include disclaimers. \"\n",
    "        \"Focus on clear, real-world intuition about audio features, lyrical patterns, \"\n",
    "        \"genre cues, and model attribution.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "def call_llm_for_popularity_and_explanation(prompt: str) -> dict:\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=prompt,\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=900\n",
    "    )\n",
    "\n",
    "    raw_text = response.output[0].content[0].text.strip()\n",
    "\n",
    "    # Remove any ```json ...``` or ```\n",
    "    raw_text = raw_text.replace(\"```json\", \"\")\n",
    "    raw_text = raw_text.replace(\"```\", \"\")\n",
    "    raw_text = raw_text.strip()\n",
    "\n",
    "    # first try direct json parse\n",
    "    try:\n",
    "        return json.loads(raw_text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # else, find outside json block using regex\n",
    "    json_matches = re.findall(r\"\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\}\", raw_text, flags=re.DOTALL)\n",
    "\n",
    "    if json_matches:\n",
    "        for match in json_matches:\n",
    "            try:\n",
    "                return json.loads(match)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # try to repair json with trailing commas\n",
    "    repaired = re.sub(r\",\\s*([}\\]])\", r\"\\1\", raw_text)\n",
    "\n",
    "    try:\n",
    "        return json.loads(repaired)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # else, say failed\n",
    "    print(\"Could not parse JSON from LLM output. Returning raw text.\")\n",
    "    return {\n",
    "        \"predicted_popularity\": None,\n",
    "        \"explanation\": raw_text\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_lyric_popularity_system(\n",
    "    df: pd.DataFrame,\n",
    "    user_lyric: str,\n",
    "    k_neighbors: int = 3,\n",
    "    top_shap_features: int = 15,\n",
    "    feature_names: List[str] = None\n",
    ") -> Dict[str, Any]:\n",
    "\n",
    "    # 1) embed target lyric\n",
    "    query_embedding = embed_lyrics(user_lyric)\n",
    "\n",
    "    # 2) retrieve neighbors using FAISS + your helper\n",
    "    neighbors = get_top_k_neighbors(df, query_embedding, k=k_neighbors)\n",
    "\n",
    "    # 3) construct feature vector for prediction\n",
    "    x_vec = construct_feature_vector(\n",
    "        target_embedding=query_embedding,\n",
    "        neighbors=neighbors,\n",
    "        audio_feature_cols=audio_feature_cols,\n",
    "        k=k_neighbors\n",
    "    )\n",
    "\n",
    "    # 4) predict popularity with LightGBM\n",
    "    pred_pop = float(model_lgb.predict(x_vec.reshape(1, -1))[0])\n",
    "\n",
    "    # 5) compute SHAP values for this sample\n",
    "    shap_vals = explainer.shap_values(x_vec.reshape(1, -1))\n",
    "\n",
    "    EMB_DIM = len(query_embedding)\n",
    "    shap_grouped = group_shap_fully(\n",
    "        shap_vals,\n",
    "        EMB_DIM=EMB_DIM,\n",
    "        audio_feature_cols=audio_feature_cols,\n",
    "        k_neighbors=k_neighbors\n",
    "    )\n",
    "\n",
    "\n",
    "    # 6) build prompt for explanation (we reconstructed this earlier)\n",
    "    prompt = build_rag_prompt_for_lyric_popularity(\n",
    "        user_lyric=user_lyric,\n",
    "        neighbors=neighbors,\n",
    "        predicted_popularity=pred_pop,\n",
    "        shap_summary=shap_grouped\n",
    "    )\n",
    "\n",
    "    # 7) call LLM for explanation ONLY\n",
    "    llm_output = call_llm_for_popularity_and_explanation(prompt)\n",
    "\n",
    "    explanation = llm_output.get(\"explanation\", \"\")\n",
    "\n",
    "    return {\n",
    "        \"predicted_popularity\": pred_pop,\n",
    "        \"explanation\": explanation,\n",
    "        \"neighbors_used\": neighbors,\n",
    "        \"prompt_sent\": prompt,\n",
    "        \"raw_llm_output\": llm_output,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can test the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted popularity: 68.35083016646738\n",
      "\n",
      "Explanation:\n",
      " The lyric 'im not cute anymore' shares thematic elements with the retrieved neighbors, particularly in its exploration of\n",
      "self-perception and identity. Neighbor 1, 'LIKEY' by TWICE, discusses themes of self-image and the desire to be perceived as\n",
      "attractive, with lines like '자꾸 드러내고 싶지' (I want to show off). Similarly, Neighbor 2, 'Mateo' by Tove Lo, touches on feelings\n",
      "of inadequacy and the pressure to fit in, as seen in 'I act so cool, but that's not me.' These thematic overlaps suggest that\n",
      "the new lyric resonates with popular topics in contemporary music, contributing to its predicted popularity score.  In terms\n",
      "of audio features, the new lyric's predicted popularity is influenced by its similarity to the audio characteristics of the\n",
      "neighbors. Neighbor 1 has a bright and energetic sound, with a high spectral centroid and tempo, which are common in upbeat\n",
      "pop songs. Neighbor 2, while slightly less energetic, still maintains a lively tempo and a rich harmonic texture, indicated\n",
      "by its spectral contrast values. These audio features suggest that the new lyric could be paired with a vibrant and catchy\n",
      "musical arrangement, enhancing its appeal.  The SHAP feature-attribution summary highlights the significant contributions of\n",
      "the target embedding and Neighbor 2's embedding to the prediction. The positive contribution from Neighbor 2's embedding\n",
      "(+0.194) indicates a strong alignment in lyrical themes and potential musical style. Additionally, the model's attribution to\n",
      "audio features such as spectral contrast and MFCCs suggests that these elements are crucial in defining the song's potential\n",
      "success. The positive influence of spectral contrast and MFCCs in Neighbor 1 further supports the idea that a dynamic and\n",
      "textured sound is favorable.  Overall, the predicted popularity score of 68.35 is justified by the thematic relevance of the\n",
      "new lyric to popular songs and the potential for an engaging musical composition. The alignment with successful audio\n",
      "features from the neighbors, combined with the model's emphasis on embedding similarities, provides a coherent explanation\n",
      "for the predicted score. This suggests that the new lyric has a strong potential to resonate with audiences if paired with\n",
      "the right musical production.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "test_lyric = \"im not cute anymore\"\n",
    "result = rag_lyric_popularity_system(df, test_lyric, k_neighbors=3)\n",
    "\n",
    "print(\"Predicted popularity:\", result[\"predicted_popularity\"])\n",
    "print(\"\\nExplanation:\\n\", textwrap.fill(result[\"explanation\"], width=125))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trems lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted popularity: 67.6863339419813\n",
      "\n",
      "Explanation:\n",
      " The new lyric shares thematic elements with its neighbors, particularly in its introspective and emotional tone. For\n",
      "instance, Neighbor 1, 'So What' by BTS, features lines about dealing with internal struggles and seeking validation, similar\n",
      "to the new lyric's exploration of feeling 'worthy of viewing' and 'desperate thinking.' Neighbor 2, 'Right Here' by Staind,\n",
      "also deals with themes of waiting and seeking attention, as seen in the repeated phrase 'right here waiting.' These thematic\n",
      "similarities suggest a resonance with listeners who appreciate introspective and emotionally charged lyrics.  In terms of\n",
      "audio features, the new lyric's predicted popularity is influenced by its similarity to songs with certain sonic\n",
      "characteristics. Neighbor 1 has a bright and energetic sound, with a high spectral centroid and tempo, which often correlates\n",
      "with engaging and lively tracks. Neighbor 2, while having a lower tempo, shares a similar spectral contrast and tonal\n",
      "quality, indicating a balance between energy and emotional depth. These audio features suggest that the new lyric might be\n",
      "set to a track that combines brightness with a steady, engaging rhythm, appealing to a broad audience.  The SHAP feature-\n",
      "attribution summary highlights the importance of the target embedding and neighbor contributions in predicting popularity.\n",
      "The positive contribution from Neighbor 1's popularity (+28.843) significantly boosts the score, indicating that the model\n",
      "sees a strong potential for the new lyric to achieve similar success. The embedding similarity with Neighbor 2 (+0.120) also\n",
      "supports this, as it suggests a close alignment in lyrical style and potential audience appeal.  Overall, the predicted\n",
      "popularity score of 67.69 is justified by the combination of lyrical themes, audio feature alignment, and the influence of\n",
      "successful neighbors. The introspective and emotionally resonant nature of the lyrics, paired with audio features that\n",
      "suggest a bright yet steady track, align well with the characteristics of popular songs in the dataset. The model's\n",
      "attribution to similar successful songs further supports the likelihood of the new lyric achieving notable popularity.\n"
     ]
    }
   ],
   "source": [
    "trem_lyrics = \"i'll take what you say. the wrong way on purpose. just to make me think. someone's paying attention. i'll take what you think. and sink under the surface. just to make me fee. like i'm worthy of viewing. delusional no. its desperate thinking. illiterate no. i just can’t read you. all that i do. is wait for you to notice. all that i get. is nothing short of. it's not what i say\"\n",
    "\n",
    "result = rag_lyric_popularity_system(df, trem_lyrics, k_neighbors=3)\n",
    "\n",
    "print(\"Predicted popularity:\", result[\"predicted_popularity\"])\n",
    "print(\"\\nExplanation:\\n\", textwrap.fill(result[\"explanation\"], width=125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted popularity: 50.53201421975274\n",
      "\n",
      "Explanation:\n",
      " The new lyric shares thematic elements with its closest neighbors, particularly the feelings of confusion and desire for\n",
      "change. For instance, Neighbor 1, 'No Way Out' by Bullet for My Valentine, expresses a struggle with internal thoughts and a\n",
      "desire to escape, similar to the lines 'Feel like im goin crazy. Outta my mind.' Neighbor 2, 'Glass' by Nekoi, also conveys a\n",
      "sense of being lost and tired of feeling stuck, which resonates with 'Stuck in a rut. never knowing what.' These thematic\n",
      "similarities contribute to the predicted popularity score by aligning with common emotional narratives in popular music.  In\n",
      "terms of audio features, the new lyric is predicted to have a moderate tempo and energy level, akin to Neighbor 1, which has\n",
      "a tempo of 112.5 BPM and a relatively high energy level. The spectral features such as spectral centroid and zero-crossing\n",
      "rate suggest a bright and dynamic sound, similar to the audio characteristics of Neighbor 3, 'Right Left Wrong' by Three Days\n",
      "Grace. This brightness and energy are often associated with engaging and popular tracks.  The SHAP feature-attribution\n",
      "summary highlights that Neighbor 1 had a positive influence on the prediction due to its higher popularity and similar audio\n",
      "features, such as zero-crossing rate and spectral contrast. The target embedding contribution was slightly negative,\n",
      "indicating that while the new lyric shares some similarities with popular songs, it also diverges in certain aspects.\n",
      "Neighbor 2's lower similarity score and embedding contribution suggest that while thematically similar, its audio features\n",
      "did not align as closely with the new lyric.  Overall, the predicted popularity score of 50.53 is justified by the\n",
      "combination of lyrical themes that resonate with popular songs and audio features that suggest a bright and energetic sound.\n",
      "The influence of Neighbor 1's popularity and audio characteristics played a significant role in shaping the prediction, while\n",
      "the thematic alignment with Neighbor 2 and 3 supports the emotional depth of the new lyric.\n"
     ]
    }
   ],
   "source": [
    "trem_lyrics = \"Feels like im running around. Feel like im running 'round again. Don't know how Or where it started. Feel like im goin crazy. Outta my mind. Outta space. Outta time. By the time I survive. I don't wanna move. I don't wanna stay. And either way. It always ends in heartbreak. I don't wanna be here anyway. You make it hard You make it hard for me to Stay why don't 'Cha give it up for me. And I just wanna feel Something. Stuck in a rut. never knowing what. I'm outta touch. Mmm mmm. I'm outta luck. Save me now. I'm outta touch. And I don't even want touch this I don't wanna do anything more. Anything much. I betcha know. I betcha know. I betcha know. I…I.  think I'd start over again. I think I'd start over again. I think I'd start over again oh. I think I'd start over again. I would I will if I could then I should.Start over. It's my time. My life. It's my right. My crime.I 'm alright. No I'm fine I'm fine I'm fine! \"\n",
    "\n",
    "result = rag_lyric_popularity_system(df, trem_lyrics, k_neighbors=3)\n",
    "\n",
    "print(\"Predicted popularity:\", result[\"predicted_popularity\"])\n",
    "print(\"\\nExplanation:\\n\", textwrap.fill(result[\"explanation\"], width=125))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
